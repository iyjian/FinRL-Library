{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/AI4Finance-LLC/FinRL-Library/blob/master/FinRL_multiple_stock_trading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXaoZs2lh1hi"
   },
   "source": [
    "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading\n",
    "\n",
    "Tutorials to use OpenAI DRL to trade multiple stocks in one Jupyter Notebook | Presented at NeurIPS 2020: Deep RL Workshop\n",
    "\n",
    "* This blog is based on our paper: FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance, presented at NeurIPS 2020: Deep RL Workshop.\n",
    "* Check out medium blog for detailed explanations: https://towardsdatascience.com/finrl-for-quantitative-finance-tutorial-for-multiple-stock-trading-7b00763b7530\n",
    "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
    "* **Pytorch Version** \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGunVt8oLCVS"
   },
   "source": [
    "# Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HOzAKQ-SLGX6"
   },
   "source": [
    "* [1. Problem Definition](#0)\n",
    "* [2. Getting Started - Load Python packages](#1)\n",
    "    * [2.1. Install Packages](#1.1)    \n",
    "    * [2.2. Check Additional Packages](#1.2)\n",
    "    * [2.3. Import Packages](#1.3)\n",
    "    * [2.4. Create Folders](#1.4)\n",
    "* [3. Download Data](#2)\n",
    "* [4. Preprocess Data](#3)        \n",
    "    * [4.1. Technical Indicators](#3.1)\n",
    "    * [4.2. Perform Feature Engineering](#3.2)\n",
    "* [5.Build Environment](#4)  \n",
    "    * [5.1. Training & Trade Data Split](#4.1)\n",
    "    * [5.2. User-defined Environment](#4.2)   \n",
    "    * [5.3. Initialize Environment](#4.3)    \n",
    "* [6.Implement DRL Algorithms](#5)  \n",
    "* [7.Backtesting Performance](#6)  \n",
    "    * [7.1. BackTestStats](#6.1)\n",
    "    * [7.2. BackTestPlot](#6.2)   \n",
    "    * [7.3. Baseline Stats](#6.3)   \n",
    "    * [7.3. Compare to Stock Market Index](#6.4)             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sApkDlD9LIZv"
   },
   "source": [
    "<a id='0'></a>\n",
    "# Part 1. Problem Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjLD2TZSLKZ-"
   },
   "source": [
    "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
    "\n",
    "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
    "\n",
    "\n",
    "* Action: The action space describes the allowed actions that the agent interacts with the\n",
    "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
    "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
    "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
    "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
    "\n",
    "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
    "values at state s′ and s, respectively\n",
    "\n",
    "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
    "our trading agent observes many different features to better learn in an interactive environment.\n",
    "\n",
    "* Environment: Dow 30 consituents\n",
    "\n",
    "\n",
    "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ffsre789LY08"
   },
   "source": [
    "<a id='1'></a>\n",
    "# Part 2. Getting Started- Load Python Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uy5_PTmOh1hj"
   },
   "source": [
    "<a id='1.1'></a>\n",
    "## 2.1. Install all the packages through FinRL library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "osBHhVysOEzi"
   },
   "source": [
    "\n",
    "<a id='1.2'></a>\n",
    "## 2.2. Check if the additional packages needed are present, if not install them. \n",
    "* Yahoo Finance API\n",
    "* pandas\n",
    "* numpy\n",
    "* matplotlib\n",
    "* stockstats\n",
    "* OpenAI gym\n",
    "* stable-baselines\n",
    "* tensorflow\n",
    "* pyfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGv01K8Sh1hn"
   },
   "source": [
    "<a id='1.3'></a>\n",
    "## 2.3. Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lPqeTTwoh1hn",
    "outputId": "c437c266-2780-4c50-af8b-6868e7fdaa1f"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# matplotlib.use('Agg')\n",
    "import datetime\n",
    "\n",
    "%matplotlib inline\n",
    "from finrl.config import config\n",
    "from finrl.marketdata.yahoodownloader import YahooDownloader\n",
    "from finrl.preprocessing.preprocessors import FeatureEngineer\n",
    "from finrl.preprocessing.data import data_split\n",
    "from finrl.env.env_stocktrading import StockTradingEnv\n",
    "from finrl.model.models import DRLAgent\n",
    "# from finrl.trade.backtest import BackTestStats, BaselineStats, BackTestPlot\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../FinRL-Library\")\n",
    "\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2owTj985RW4"
   },
   "source": [
    "<a id='1.4'></a>\n",
    "## 2.4. Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "w9A8CN5R5PuZ"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./\" + config.DATA_SAVE_DIR):\n",
    "    os.makedirs(\"./\" + config.DATA_SAVE_DIR)\n",
    "if not os.path.exists(\"./\" + config.TRAINED_MODEL_DIR):\n",
    "    os.makedirs(\"./\" + config.TRAINED_MODEL_DIR)\n",
    "if not os.path.exists(\"./\" + config.TENSORBOARD_LOG_DIR):\n",
    "    os.makedirs(\"./\" + config.TENSORBOARD_LOG_DIR)\n",
    "if not os.path.exists(\"./\" + config.RESULTS_DIR):\n",
    "    os.makedirs(\"./\" + config.RESULTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A289rQWMh1hq"
   },
   "source": [
    "<a id='2'></a>\n",
    "# Part 3. Download Data\n",
    "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
    "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
    "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NPeQ7iS-LoMm"
   },
   "source": [
    "\n",
    "\n",
    "-----\n",
    "class YahooDownloader:\n",
    "    Provides methods for retrieving daily stock data from\n",
    "    Yahoo Finance API\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "        start_date : str\n",
    "            start date of the data (modified from config.py)\n",
    "        end_date : str\n",
    "            end date of the data (modified from config.py)\n",
    "        ticker_list : list\n",
    "            a list of stock tickers (modified from config.py)\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    fetch_data()\n",
    "        Fetches data from yahoo API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "h3XJnvrbLp-C",
    "outputId": "87dea23f-469d-4e9d-de91-0f8a74929de2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2000-01-01'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py start_date is a string\n",
    "config.START_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "FUnY8WEfLq3C",
    "outputId": "c635ae69-a13e-408f-d932-9d386d1d6dcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021-01-01'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from config.py end_date is a string\n",
    "config.END_DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JzqRRTOX6aFu",
    "outputId": "d3baf63f-948a-49f9-f6f2-b7241971b8ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AAPL', 'MSFT', 'JPM', 'V', 'RTX', 'PG', 'GS', 'NKE', 'DIS', 'AXP', 'HD', 'INTC', 'WMT', 'IBM', 'MRK', 'UNH', 'KO', 'CAT', 'TRV', 'JNJ', 'CVX', 'MCD', 'VZ', 'CSCO', 'XOM', 'BA', 'MMM', 'PFE', 'WBA', 'DD']\n"
     ]
    }
   ],
   "source": [
    "print(config.DOW_30_TICKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCKm4om-s9kE",
    "outputId": "932583d8-f98b-4243-c02d-375f7272db1a"
   },
   "outputs": [],
   "source": [
    "# df = YahooDownloader(start_date = '2009-01-01',\n",
    "#                      end_date = '2021-01-01',\n",
    "#                      ticker_list = config.DOW_30_TICKER).fetch_data()\n",
    "\n",
    "import pickle\n",
    "df = pickle.load(open('./dow_data.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CV3HrZHLh1hy",
    "outputId": "b7b78172-8c8a-41c9-c8a6-0167edb9bd11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22680, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "4hYkeaPiICHS",
    "outputId": "ce9d7463-a74c-4917-c96d-848a1e8ad493"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>tic</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>43.075001</td>\n",
       "      <td>42.314999</td>\n",
       "      <td>41.442081</td>\n",
       "      <td>102223600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>99.730003</td>\n",
       "      <td>99.730003</td>\n",
       "      <td>98.220001</td>\n",
       "      <td>94.095047</td>\n",
       "      <td>2746700</td>\n",
       "      <td>AXP</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>295.750000</td>\n",
       "      <td>296.989990</td>\n",
       "      <td>295.399994</td>\n",
       "      <td>282.886383</td>\n",
       "      <td>2978900</td>\n",
       "      <td>BA</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>158.300003</td>\n",
       "      <td>159.389999</td>\n",
       "      <td>156.029999</td>\n",
       "      <td>144.235184</td>\n",
       "      <td>5108400</td>\n",
       "      <td>CAT</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>38.669998</td>\n",
       "      <td>38.950001</td>\n",
       "      <td>38.430000</td>\n",
       "      <td>35.173683</td>\n",
       "      <td>20135700</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        open        high         low       close     volume  \\\n",
       "0  2018-01-02   42.540001   43.075001   42.314999   41.442081  102223600   \n",
       "1  2018-01-02   99.730003   99.730003   98.220001   94.095047    2746700   \n",
       "2  2018-01-02  295.750000  296.989990  295.399994  282.886383    2978900   \n",
       "3  2018-01-02  158.300003  159.389999  156.029999  144.235184    5108400   \n",
       "4  2018-01-02   38.669998   38.950001   38.430000   35.173683   20135700   \n",
       "\n",
       "    tic  day  \n",
       "0  AAPL    1  \n",
       "1   AXP    1  \n",
       "2    BA    1  \n",
       "3   CAT    1  \n",
       "4  CSCO    1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(['date','tic'],ignore_index=True).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uqC6c40Zh1iH"
   },
   "source": [
    "# Part 4: Preprocess Data\n",
    "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
    "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
    "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully added technical indicators\n",
      "Successfully added turbulence index\n"
     ]
    }
   ],
   "source": [
    "fe = FeatureEngineer(\n",
    "                    use_technical_indicator=True,\n",
    "                    tech_indicator_list = config.TECHNICAL_INDICATORS_LIST,\n",
    "                    use_turbulence=True,\n",
    "                    user_defined_feature = False)\n",
    "\n",
    "processed = fe.preprocess_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ticker = processed[\"tic\"].unique().tolist()\n",
    "list_date = list(pd.date_range(processed['date'].min(),processed['date'].max()).astype(str))\n",
    "combination = list(itertools.product(list_date,list_ticker))\n",
    "\n",
    "processed_full = pd.DataFrame(combination,columns=[\"date\",\"tic\"]).merge(processed,on=[\"date\",\"tic\"],how=\"left\")\n",
    "processed_full = processed_full[processed_full['date'].isin(processed['date'])]\n",
    "processed_full = processed_full.sort_values(['date','tic'])\n",
    "\n",
    "processed_full = processed_full.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "grvhGJJII3Xn",
    "outputId": "91d09c37-b0e9-4c5c-d532-967e40d11f41"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>43.075001</td>\n",
       "      <td>42.314999</td>\n",
       "      <td>41.442081</td>\n",
       "      <td>102223600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>41.442081</td>\n",
       "      <td>41.442081</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>AXP</td>\n",
       "      <td>99.730003</td>\n",
       "      <td>99.730003</td>\n",
       "      <td>98.220001</td>\n",
       "      <td>94.095047</td>\n",
       "      <td>2746700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.095047</td>\n",
       "      <td>94.095047</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>BA</td>\n",
       "      <td>295.750000</td>\n",
       "      <td>296.989990</td>\n",
       "      <td>295.399994</td>\n",
       "      <td>282.886383</td>\n",
       "      <td>2978900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>282.886383</td>\n",
       "      <td>282.886383</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>CAT</td>\n",
       "      <td>158.300003</td>\n",
       "      <td>159.389999</td>\n",
       "      <td>156.029999</td>\n",
       "      <td>144.235184</td>\n",
       "      <td>5108400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>144.235184</td>\n",
       "      <td>144.235184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>38.669998</td>\n",
       "      <td>38.950001</td>\n",
       "      <td>38.430000</td>\n",
       "      <td>35.173683</td>\n",
       "      <td>20135700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>35.173683</td>\n",
       "      <td>35.173683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>CVX</td>\n",
       "      <td>125.709999</td>\n",
       "      <td>127.739998</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>111.714676</td>\n",
       "      <td>5626000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>111.714676</td>\n",
       "      <td>111.714676</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>DD</td>\n",
       "      <td>101.863419</td>\n",
       "      <td>102.745842</td>\n",
       "      <td>101.621460</td>\n",
       "      <td>92.456123</td>\n",
       "      <td>5220700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.456123</td>\n",
       "      <td>92.456123</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>DIS</td>\n",
       "      <td>108.949997</td>\n",
       "      <td>111.809998</td>\n",
       "      <td>108.559998</td>\n",
       "      <td>108.726067</td>\n",
       "      <td>11014300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>108.726067</td>\n",
       "      <td>108.726067</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>GS</td>\n",
       "      <td>257.769989</td>\n",
       "      <td>257.910004</td>\n",
       "      <td>253.919998</td>\n",
       "      <td>241.290482</td>\n",
       "      <td>2258300.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>241.290482</td>\n",
       "      <td>241.290482</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>HD</td>\n",
       "      <td>190.210007</td>\n",
       "      <td>190.720001</td>\n",
       "      <td>188.009995</td>\n",
       "      <td>174.873688</td>\n",
       "      <td>4684700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>174.873688</td>\n",
       "      <td>174.873688</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   tic        open        high         low       close  \\\n",
       "0  2018-01-02  AAPL   42.540001   43.075001   42.314999   41.442081   \n",
       "1  2018-01-02   AXP   99.730003   99.730003   98.220001   94.095047   \n",
       "2  2018-01-02    BA  295.750000  296.989990  295.399994  282.886383   \n",
       "3  2018-01-02   CAT  158.300003  159.389999  156.029999  144.235184   \n",
       "4  2018-01-02  CSCO   38.669998   38.950001   38.430000   35.173683   \n",
       "5  2018-01-02   CVX  125.709999  127.739998  125.540001  111.714676   \n",
       "6  2018-01-02    DD  101.863419  102.745842  101.621460   92.456123   \n",
       "7  2018-01-02   DIS  108.949997  111.809998  108.559998  108.726067   \n",
       "8  2018-01-02    GS  257.769989  257.910004  253.919998  241.290482   \n",
       "9  2018-01-02    HD  190.210007  190.720001  188.009995  174.873688   \n",
       "\n",
       "        volume  day  macd   boll_ub    boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  102223600.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "1    2746700.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "2    2978900.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "3    5108400.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "4   20135700.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "5    5626000.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "6    5220700.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "7   11014300.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "8    2258300.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "9    4684700.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma  turbulence  \n",
       "0     41.442081     41.442081         0.0  \n",
       "1     94.095047     94.095047         0.0  \n",
       "2    282.886383    282.886383         0.0  \n",
       "3    144.235184    144.235184         0.0  \n",
       "4     35.173683     35.173683         0.0  \n",
       "5    111.714676    111.714676         0.0  \n",
       "6     92.456123     92.456123         0.0  \n",
       "7    108.726067    108.726067         0.0  \n",
       "8    241.290482    241.290482         0.0  \n",
       "9    174.873688    174.873688         0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_full.sort_values(['date','tic'],ignore_index=True).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QsYaY0Dh1iw"
   },
   "source": [
    "<a id='4'></a>\n",
    "# Part 5. Design Environment\n",
    "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
    "\n",
    "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
    "\n",
    "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TOhcryx44bb"
   },
   "source": [
    "## Training data split: 2009-01-01 to 2018-12-31\n",
    "## Trade data split: 2019-01-01 to 2020-09-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0qaVGjLtgbI",
    "outputId": "c98aeb90-84e3-4b83-9671-d679f3fe148f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7530\n",
      "15150\n"
     ]
    }
   ],
   "source": [
    "train = data_split(processed_full, '2009-01-01','2019-01-01')\n",
    "trade = data_split(processed_full, '2019-01-01','2021-01-01')\n",
    "print(len(train))\n",
    "print(len(trade))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "id": "p52zNCOhTtLR",
    "outputId": "c41f9be0-a99f-4108-a427-3112b6bd4129"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>42.540001</td>\n",
       "      <td>43.075001</td>\n",
       "      <td>42.314999</td>\n",
       "      <td>41.442081</td>\n",
       "      <td>102223600.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>41.442081</td>\n",
       "      <td>41.442081</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>AXP</td>\n",
       "      <td>99.730003</td>\n",
       "      <td>99.730003</td>\n",
       "      <td>98.220001</td>\n",
       "      <td>94.095047</td>\n",
       "      <td>2746700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.095047</td>\n",
       "      <td>94.095047</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>BA</td>\n",
       "      <td>295.750000</td>\n",
       "      <td>296.989990</td>\n",
       "      <td>295.399994</td>\n",
       "      <td>282.886383</td>\n",
       "      <td>2978900.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>282.886383</td>\n",
       "      <td>282.886383</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>CAT</td>\n",
       "      <td>158.300003</td>\n",
       "      <td>159.389999</td>\n",
       "      <td>156.029999</td>\n",
       "      <td>144.235184</td>\n",
       "      <td>5108400.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>144.235184</td>\n",
       "      <td>144.235184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-02</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>38.669998</td>\n",
       "      <td>38.950001</td>\n",
       "      <td>38.430000</td>\n",
       "      <td>35.173683</td>\n",
       "      <td>20135700.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.44868</td>\n",
       "      <td>41.428266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.666667</td>\n",
       "      <td>100.0</td>\n",
       "      <td>35.173683</td>\n",
       "      <td>35.173683</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   tic        open        high         low       close  \\\n",
       "0  2018-01-02  AAPL   42.540001   43.075001   42.314999   41.442081   \n",
       "0  2018-01-02   AXP   99.730003   99.730003   98.220001   94.095047   \n",
       "0  2018-01-02    BA  295.750000  296.989990  295.399994  282.886383   \n",
       "0  2018-01-02   CAT  158.300003  159.389999  156.029999  144.235184   \n",
       "0  2018-01-02  CSCO   38.669998   38.950001   38.430000   35.173683   \n",
       "\n",
       "        volume  day  macd   boll_ub    boll_lb  rsi_30     cci_30  dx_30  \\\n",
       "0  102223600.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "0    2746700.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "0    2978900.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "0    5108400.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "0   20135700.0  1.0   0.0  41.44868  41.428266     0.0  66.666667  100.0   \n",
       "\n",
       "   close_30_sma  close_60_sma  turbulence  \n",
       "0     41.442081     41.442081         0.0  \n",
       "0     94.095047     94.095047         0.0  \n",
       "0    282.886383    282.886383         0.0  \n",
       "0    144.235184    144.235184         0.0  \n",
       "0     35.173683     35.173683         0.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "k9zU9YaTTvFq",
    "outputId": "705f46e4-0529-4ef5-d182-c2a1337397a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>tic</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>day</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "      <th>turbulence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>38.722500</td>\n",
       "      <td>39.712502</td>\n",
       "      <td>38.557499</td>\n",
       "      <td>38.562561</td>\n",
       "      <td>148158800.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-2.019903</td>\n",
       "      <td>44.572026</td>\n",
       "      <td>35.497554</td>\n",
       "      <td>37.865996</td>\n",
       "      <td>-91.567852</td>\n",
       "      <td>42.250809</td>\n",
       "      <td>41.287324</td>\n",
       "      <td>46.557656</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>AXP</td>\n",
       "      <td>93.910004</td>\n",
       "      <td>96.269997</td>\n",
       "      <td>93.769997</td>\n",
       "      <td>92.319603</td>\n",
       "      <td>4175400.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-3.414037</td>\n",
       "      <td>110.237769</td>\n",
       "      <td>84.427489</td>\n",
       "      <td>41.203549</td>\n",
       "      <td>-97.751316</td>\n",
       "      <td>26.709418</td>\n",
       "      <td>100.019656</td>\n",
       "      <td>100.588130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>BA</td>\n",
       "      <td>316.190002</td>\n",
       "      <td>323.950012</td>\n",
       "      <td>313.709991</td>\n",
       "      <td>314.645142</td>\n",
       "      <td>3292200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-5.550593</td>\n",
       "      <td>339.116375</td>\n",
       "      <td>287.252015</td>\n",
       "      <td>47.008584</td>\n",
       "      <td>-21.712382</td>\n",
       "      <td>13.611972</td>\n",
       "      <td>314.427160</td>\n",
       "      <td>331.956148</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>CAT</td>\n",
       "      <td>124.029999</td>\n",
       "      <td>127.879997</td>\n",
       "      <td>123.000000</td>\n",
       "      <td>118.671188</td>\n",
       "      <td>4783200.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.683125</td>\n",
       "      <td>125.711463</td>\n",
       "      <td>109.507839</td>\n",
       "      <td>48.226578</td>\n",
       "      <td>-5.121417</td>\n",
       "      <td>0.873480</td>\n",
       "      <td>118.172271</td>\n",
       "      <td>120.376044</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-02</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>42.279999</td>\n",
       "      <td>43.200001</td>\n",
       "      <td>42.209999</td>\n",
       "      <td>40.057236</td>\n",
       "      <td>23833500.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.952338</td>\n",
       "      <td>46.451449</td>\n",
       "      <td>37.116620</td>\n",
       "      <td>44.871084</td>\n",
       "      <td>-87.518839</td>\n",
       "      <td>29.529378</td>\n",
       "      <td>42.163155</td>\n",
       "      <td>42.439686</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   tic        open        high         low       close  \\\n",
       "0  2019-01-02  AAPL   38.722500   39.712502   38.557499   38.562561   \n",
       "0  2019-01-02   AXP   93.910004   96.269997   93.769997   92.319603   \n",
       "0  2019-01-02    BA  316.190002  323.950012  313.709991  314.645142   \n",
       "0  2019-01-02   CAT  124.029999  127.879997  123.000000  118.671188   \n",
       "0  2019-01-02  CSCO   42.279999   43.200001   42.209999   40.057236   \n",
       "\n",
       "        volume  day      macd     boll_ub     boll_lb     rsi_30     cci_30  \\\n",
       "0  148158800.0  2.0 -2.019903   44.572026   35.497554  37.865996 -91.567852   \n",
       "0    4175400.0  2.0 -3.414037  110.237769   84.427489  41.203549 -97.751316   \n",
       "0    3292200.0  2.0 -5.550593  339.116375  287.252015  47.008584 -21.712382   \n",
       "0    4783200.0  2.0 -0.683125  125.711463  109.507839  48.226578  -5.121417   \n",
       "0   23833500.0  2.0 -0.952338   46.451449   37.116620  44.871084 -87.518839   \n",
       "\n",
       "       dx_30  close_30_sma  close_60_sma  turbulence  \n",
       "0  42.250809     41.287324     46.557656         0.0  \n",
       "0  26.709418    100.019656    100.588130         0.0  \n",
       "0  13.611972    314.427160    331.956148         0.0  \n",
       "0   0.873480    118.172271    120.376044         0.0  \n",
       "0  29.529378     42.163155     42.439686         0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYN573SOHhxG",
    "outputId": "187c6d1b-3e91-40f8-dafd-230d787f2ee1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['macd',\n",
       " 'boll_ub',\n",
       " 'boll_lb',\n",
       " 'rsi_30',\n",
       " 'cci_30',\n",
       " 'dx_30',\n",
       " 'close_30_sma',\n",
       " 'close_60_sma']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.TECHNICAL_INDICATORS_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2zqII8rMIqn",
    "outputId": "8a2c943b-1be4-4b8d-b64f-666e0852b7e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 30, State Space: 301\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = 1 + 2*stock_dimension + len(config.TECHNICAL_INDICATORS_LIST)*stock_dimension\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "AWyp84Ltto19"
   },
   "outputs": [],
   "source": [
    "env_kwargs = {\n",
    "    \"hmax\": 100, \n",
    "    \"initial_amount\": 1000000, \n",
    "    \"buy_cost_pct\": 0.001,\n",
    "    \"sell_cost_pct\": 0.001,\n",
    "    \"state_space\": state_space, \n",
    "    \"stock_dim\": stock_dimension, \n",
    "    \"tech_indicator_list\": config.TECHNICAL_INDICATORS_LIST, \n",
    "    \"action_space\": stock_dimension, \n",
    "    \"reward_scaling\": 1e-4\n",
    "    \n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df = train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64EoqOrQjiVf"
   },
   "source": [
    "## Environment for Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwSvvPjutpqS",
    "outputId": "406e5ec3-28ba-4a72-9b22-0d031f7bf9a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n"
     ]
    }
   ],
   "source": [
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(type(env_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HMNR5nHjh1iz"
   },
   "source": [
    "<a id='5'></a>\n",
    "# Part 6: Implement DRL Algorithms\n",
    "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
    "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
    "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
    "design their own DRL algorithms by adapting these DRL algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "364PsqckttcQ"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YDmqOyF9h1iz"
   },
   "source": [
    "### Model Training: 5 models, A2C DDPG, PPO, TD3, SAC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uijiWgkuh1jB"
   },
   "source": [
    "### Model 1: A2C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GUCnkn-HIbmj",
    "outputId": "2fdb297a-8d35-4c7e-806f-de859d70e19e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GVpkWGqH4-D",
    "outputId": "9eb09ba2-fc4b-46a1-ea3d-bd9b3bfefffd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to tensorboard_log/a2c/a2c_1\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.09e+05  |\n",
      "|    total_cost         | 2.68e+04  |\n",
      "|    total_reward       | -9.07e+04 |\n",
      "|    total_reward_pct   | -9.07     |\n",
      "|    total_trades       | 5855      |\n",
      "| time/                 |           |\n",
      "|    fps                | 377       |\n",
      "|    iterations         | 100       |\n",
      "|    time_elapsed       | 1         |\n",
      "|    total_timesteps    | 500       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -8.53e+15 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 99        |\n",
      "|    policy_loss        | -240      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 38.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.51e+05  |\n",
      "|    total_cost         | 1.98e+04  |\n",
      "|    total_reward       | -4.89e+04 |\n",
      "|    total_reward_pct   | -4.89     |\n",
      "|    total_trades       | 5438      |\n",
      "| time/                 |           |\n",
      "|    fps                | 381       |\n",
      "|    iterations         | 200       |\n",
      "|    time_elapsed       | 2         |\n",
      "|    total_timesteps    | 1000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -1.27e+05 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 199       |\n",
      "|    policy_loss        | -118      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 9.73      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.15e+05  |\n",
      "|    total_cost         | 1.37e+04  |\n",
      "|    total_reward       | -8.47e+04 |\n",
      "|    total_reward_pct   | -8.47     |\n",
      "|    total_trades       | 4669      |\n",
      "| time/                 |           |\n",
      "|    fps                | 375       |\n",
      "|    iterations         | 300       |\n",
      "|    time_elapsed       | 3         |\n",
      "|    total_timesteps    | 1500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -81.2     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 299       |\n",
      "|    policy_loss        | -36.2     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 0.855     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 1.65e+04 |\n",
      "|    total_reward       | 1.89e+03 |\n",
      "|    total_reward_pct   | 0.189    |\n",
      "|    total_trades       | 4934     |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 400      |\n",
      "|    time_elapsed       | 5        |\n",
      "|    total_timesteps    | 2000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 399      |\n",
      "|    policy_loss        | -41.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.7      |\n",
      "------------------------------------\n",
      "day: 250, episode: 10\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 916723.76\n",
      "total_reward: -83276.24\n",
      "total_cost: 10136.51\n",
      "total_trades: 4242\n",
      "Sharpe: -0.424\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.17e+05  |\n",
      "|    total_cost         | 1.01e+04  |\n",
      "|    total_reward       | -8.33e+04 |\n",
      "|    total_reward_pct   | -8.33     |\n",
      "|    total_trades       | 4242      |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 500       |\n",
      "|    time_elapsed       | 6         |\n",
      "|    total_timesteps    | 2500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.8     |\n",
      "|    explained_variance | -358      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 499       |\n",
      "|    policy_loss        | -95.3     |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 7.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.24e+05  |\n",
      "|    total_cost         | 7.52e+03  |\n",
      "|    total_reward       | -7.56e+04 |\n",
      "|    total_reward_pct   | -7.56     |\n",
      "|    total_trades       | 4160      |\n",
      "| time/                 |           |\n",
      "|    fps                | 373       |\n",
      "|    iterations         | 600       |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 3000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -149      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 599       |\n",
      "|    policy_loss        | -67.8     |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 3.5       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.05e+05  |\n",
      "|    total_cost         | 5.9e+03   |\n",
      "|    total_reward       | -9.52e+04 |\n",
      "|    total_reward_pct   | -9.52     |\n",
      "|    total_trades       | 4142      |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 700       |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 3500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | -38.9     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 699       |\n",
      "|    policy_loss        | 64.3      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 3.51      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.59e+05  |\n",
      "|    total_cost         | 8.32e+03  |\n",
      "|    total_reward       | -4.09e+04 |\n",
      "|    total_reward_pct   | -4.09     |\n",
      "|    total_trades       | 4239      |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 800       |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 4000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 799       |\n",
      "|    policy_loss        | 68.4      |\n",
      "|    std                | 1         |\n",
      "|    value_loss         | 4.59      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.45e+05  |\n",
      "|    total_cost         | 8.3e+03   |\n",
      "|    total_reward       | -5.49e+04 |\n",
      "|    total_reward_pct   | -5.49     |\n",
      "|    total_trades       | 4265      |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 900       |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 4500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.7     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 899       |\n",
      "|    policy_loss        | 74.5      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.84      |\n",
      "-------------------------------------\n",
      "day: 250, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1003605.79\n",
      "total_reward: 3605.79\n",
      "total_cost: 5648.36\n",
      "total_trades: 3971\n",
      "Sharpe: 0.107\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 5.65e+03 |\n",
      "|    total_reward       | 3.61e+03 |\n",
      "|    total_reward_pct   | 0.361    |\n",
      "|    total_trades       | 3971     |\n",
      "| time/                 |          |\n",
      "|    fps                | 374      |\n",
      "|    iterations         | 1000     |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 5000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 999      |\n",
      "|    policy_loss        | -79.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 5.71     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 6.52e+03 |\n",
      "|    total_reward       | 1.69e+03 |\n",
      "|    total_reward_pct   | 0.169    |\n",
      "|    total_trades       | 3862     |\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 1100     |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 5500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -42.8    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1099     |\n",
      "|    policy_loss        | -84.9    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 4.54     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.66e+05  |\n",
      "|    total_cost         | 5.96e+03  |\n",
      "|    total_reward       | -3.36e+04 |\n",
      "|    total_reward_pct   | -3.36     |\n",
      "|    total_trades       | 3647      |\n",
      "| time/                 |           |\n",
      "|    fps                | 375       |\n",
      "|    iterations         | 1200      |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 6000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -42.9     |\n",
      "|    explained_variance | -73       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1199      |\n",
      "|    policy_loss        | 76.4      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.13      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+06 |\n",
      "|    total_cost         | 6.87e+03 |\n",
      "|    total_reward       | 1.77e+04 |\n",
      "|    total_reward_pct   | 1.77     |\n",
      "|    total_trades       | 3534     |\n",
      "| time/                 |          |\n",
      "|    fps                | 375      |\n",
      "|    iterations         | 1300     |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 6500     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1299     |\n",
      "|    policy_loss        | -25.1    |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 0.555    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.55e+05 |\n",
      "|    total_cost         | 7.2e+03  |\n",
      "|    total_reward       | -4.5e+04 |\n",
      "|    total_reward_pct   | -4.5     |\n",
      "|    total_trades       | 3630     |\n",
      "| time/                 |          |\n",
      "|    fps                | 376      |\n",
      "|    iterations         | 1400     |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 7000     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43      |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 1399     |\n",
      "|    policy_loss        | 33.4     |\n",
      "|    std                | 1.01     |\n",
      "|    value_loss         | 1.76     |\n",
      "------------------------------------\n",
      "day: 250, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 963416.65\n",
      "total_reward: -36583.35\n",
      "total_cost: 8950.38\n",
      "total_trades: 3922\n",
      "Sharpe: -0.130\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.63e+05  |\n",
      "|    total_cost         | 8.95e+03  |\n",
      "|    total_reward       | -3.66e+04 |\n",
      "|    total_reward_pct   | -3.66     |\n",
      "|    total_trades       | 3922      |\n",
      "| time/                 |           |\n",
      "|    fps                | 374       |\n",
      "|    iterations         | 1500      |\n",
      "|    time_elapsed       | 20        |\n",
      "|    total_timesteps    | 7500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1499      |\n",
      "|    policy_loss        | 122       |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 8.19      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.52e+05  |\n",
      "|    total_cost         | 7.55e+03  |\n",
      "|    total_reward       | -4.77e+04 |\n",
      "|    total_reward_pct   | -4.77     |\n",
      "|    total_trades       | 3556      |\n",
      "| time/                 |           |\n",
      "|    fps                | 375       |\n",
      "|    iterations         | 1600      |\n",
      "|    time_elapsed       | 21        |\n",
      "|    total_timesteps    | 8000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1599      |\n",
      "|    policy_loss        | 73.6      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 3.02      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.4e+05   |\n",
      "|    total_cost         | 7.12e+03  |\n",
      "|    total_reward       | -6.04e+04 |\n",
      "|    total_reward_pct   | -6.04     |\n",
      "|    total_trades       | 3642      |\n",
      "| time/                 |           |\n",
      "|    fps                | 374       |\n",
      "|    iterations         | 1700      |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 8500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43       |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1699      |\n",
      "|    policy_loss        | 59.3      |\n",
      "|    std                | 1.01      |\n",
      "|    value_loss         | 4.84      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.53e+05  |\n",
      "|    total_cost         | 7.23e+03  |\n",
      "|    total_reward       | -4.75e+04 |\n",
      "|    total_reward_pct   | -4.75     |\n",
      "|    total_trades       | 3743      |\n",
      "| time/                 |           |\n",
      "|    fps                | 374       |\n",
      "|    iterations         | 1800      |\n",
      "|    time_elapsed       | 24        |\n",
      "|    total_timesteps    | 9000      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1799      |\n",
      "|    policy_loss        | 127       |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 10.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.49e+05  |\n",
      "|    total_cost         | 6.56e+03  |\n",
      "|    total_reward       | -5.13e+04 |\n",
      "|    total_reward_pct   | -5.13     |\n",
      "|    total_trades       | 3532      |\n",
      "| time/                 |           |\n",
      "|    fps                | 374       |\n",
      "|    iterations         | 1900      |\n",
      "|    time_elapsed       | 25        |\n",
      "|    total_timesteps    | 9500      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.1     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1899      |\n",
      "|    policy_loss        | -8.98     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.95      |\n",
      "-------------------------------------\n",
      "day: 250, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 901197.03\n",
      "total_reward: -98802.97\n",
      "total_cost: 7453.63\n",
      "total_trades: 4062\n",
      "Sharpe: -0.483\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.01e+05  |\n",
      "|    total_cost         | 7.45e+03  |\n",
      "|    total_reward       | -9.88e+04 |\n",
      "|    total_reward_pct   | -9.88     |\n",
      "|    total_trades       | 4062      |\n",
      "| time/                 |           |\n",
      "|    fps                | 374       |\n",
      "|    iterations         | 2000      |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 10000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -1.42e+13 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 1999      |\n",
      "|    policy_loss        | -19.2     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 1.09      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.64e+05  |\n",
      "|    total_cost         | 1.25e+04  |\n",
      "|    total_reward       | -3.57e+04 |\n",
      "|    total_reward_pct   | -3.57     |\n",
      "|    total_trades       | 4500      |\n",
      "| time/                 |           |\n",
      "|    fps                | 373       |\n",
      "|    iterations         | 2100      |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 10500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -5.33e+07 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2099      |\n",
      "|    policy_loss        | 19.8      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 0.48      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.86e+05  |\n",
      "|    total_cost         | 9.39e+03  |\n",
      "|    total_reward       | -1.35e+04 |\n",
      "|    total_reward_pct   | -1.35     |\n",
      "|    total_trades       | 3989      |\n",
      "| time/                 |           |\n",
      "|    fps                | 373       |\n",
      "|    iterations         | 2200      |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 11000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | -219      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2199      |\n",
      "|    policy_loss        | 76.2      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 4.19      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.68e+05  |\n",
      "|    total_cost         | 7.11e+03  |\n",
      "|    total_reward       | -3.19e+04 |\n",
      "|    total_reward_pct   | -3.19     |\n",
      "|    total_trades       | 3956      |\n",
      "| time/                 |           |\n",
      "|    fps                | 373       |\n",
      "|    iterations         | 2300      |\n",
      "|    time_elapsed       | 30        |\n",
      "|    total_timesteps    | 11500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2299      |\n",
      "|    policy_loss        | 97.2      |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 7.1       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.4e+05   |\n",
      "|    total_cost         | 5.14e+03  |\n",
      "|    total_reward       | -5.99e+04 |\n",
      "|    total_reward_pct   | -5.99     |\n",
      "|    total_trades       | 3681      |\n",
      "| time/                 |           |\n",
      "|    fps                | 373       |\n",
      "|    iterations         | 2400      |\n",
      "|    time_elapsed       | 32        |\n",
      "|    total_timesteps    | 12000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.2     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2399      |\n",
      "|    policy_loss        | -36.5     |\n",
      "|    std                | 1.02      |\n",
      "|    value_loss         | 5.2       |\n",
      "-------------------------------------\n",
      "day: 250, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1013875.51\n",
      "total_reward: 13875.51\n",
      "total_cost: 5714.15\n",
      "total_trades: 3767\n",
      "Sharpe: 0.167\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 5.71e+03 |\n",
      "|    total_reward       | 1.39e+04 |\n",
      "|    total_reward_pct   | 1.39     |\n",
      "|    total_trades       | 3767     |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 2500     |\n",
      "|    time_elapsed       | 33       |\n",
      "|    total_timesteps    | 12500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.3    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2499     |\n",
      "|    policy_loss        | -167     |\n",
      "|    std                | 1.02     |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.97e+05  |\n",
      "|    total_cost         | 5.91e+03  |\n",
      "|    total_reward       | -2.78e+03 |\n",
      "|    total_reward_pct   | -0.278    |\n",
      "|    total_trades       | 3860      |\n",
      "| time/                 |           |\n",
      "|    fps                | 374       |\n",
      "|    iterations         | 2600      |\n",
      "|    time_elapsed       | 34        |\n",
      "|    total_timesteps    | 13000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.4     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2599      |\n",
      "|    policy_loss        | -22.6     |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 0.589     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.73e+05  |\n",
      "|    total_cost         | 5.34e+03  |\n",
      "|    total_reward       | -2.69e+04 |\n",
      "|    total_reward_pct   | -2.69     |\n",
      "|    total_trades       | 3812      |\n",
      "| time/                 |           |\n",
      "|    fps                | 374       |\n",
      "|    iterations         | 2700      |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 13500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.5     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2699      |\n",
      "|    policy_loss        | -50       |\n",
      "|    std                | 1.03      |\n",
      "|    value_loss         | 1.42      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 1.18e+04 |\n",
      "|    total_reward       | 4.86e+04 |\n",
      "|    total_reward_pct   | 4.86     |\n",
      "|    total_trades       | 4725     |\n",
      "| time/                 |          |\n",
      "|    fps                | 373      |\n",
      "|    iterations         | 2800     |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 14000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.5    |\n",
      "|    explained_variance | -2.9     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2799     |\n",
      "|    policy_loss        | -21.2    |\n",
      "|    std                | 1.03     |\n",
      "|    value_loss         | 0.565    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.87e+05  |\n",
      "|    total_cost         | 9.53e+03  |\n",
      "|    total_reward       | -1.32e+04 |\n",
      "|    total_reward_pct   | -1.32     |\n",
      "|    total_trades       | 4584      |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 2900      |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 14500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.6     |\n",
      "|    explained_variance | -8.22     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 2899      |\n",
      "|    policy_loss        | 3.69      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.0896    |\n",
      "-------------------------------------\n",
      "day: 250, episode: 60\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1019628.80\n",
      "total_reward: 19628.80\n",
      "total_cost: 10545.33\n",
      "total_trades: 4691\n",
      "Sharpe: 0.203\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+06 |\n",
      "|    total_cost         | 1.05e+04 |\n",
      "|    total_reward       | 1.96e+04 |\n",
      "|    total_reward_pct   | 1.96     |\n",
      "|    total_trades       | 4691     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 3000     |\n",
      "|    time_elapsed       | 40       |\n",
      "|    total_timesteps    | 15000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 2999     |\n",
      "|    policy_loss        | -29.2    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.66     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 7.06e+03 |\n",
      "|    total_reward       | 2.9e+04  |\n",
      "|    total_reward_pct   | 2.9      |\n",
      "|    total_trades       | 4123     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 3100     |\n",
      "|    time_elapsed       | 41       |\n",
      "|    total_timesteps    | 15500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.6    |\n",
      "|    explained_variance | -1.87    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3099     |\n",
      "|    policy_loss        | -19.7    |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.384    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 5.53e+03 |\n",
      "|    total_reward       | 4.02e+04 |\n",
      "|    total_reward_pct   | 4.02     |\n",
      "|    total_trades       | 3810     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 3200     |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 16000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | -0.459   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3199     |\n",
      "|    policy_loss        | 22.9     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.349    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.92e+05  |\n",
      "|    total_cost         | 3.98e+03  |\n",
      "|    total_reward       | -7.73e+03 |\n",
      "|    total_reward_pct   | -0.773    |\n",
      "|    total_trades       | 3374      |\n",
      "| time/                 |           |\n",
      "|    fps                | 370       |\n",
      "|    iterations         | 3300      |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 16500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3299      |\n",
      "|    policy_loss        | 18.2      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.354     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 3.59e+03 |\n",
      "|    total_reward       | 3.27e+03 |\n",
      "|    total_reward_pct   | 0.327    |\n",
      "|    total_trades       | 3320     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 3400     |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 17000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.8    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3399     |\n",
      "|    policy_loss        | 33.8     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 0.691    |\n",
      "------------------------------------\n",
      "day: 250, episode: 70\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1062786.39\n",
      "total_reward: 62786.39\n",
      "total_cost: 4933.53\n",
      "total_trades: 3544\n",
      "Sharpe: 0.461\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.06e+06 |\n",
      "|    total_cost         | 4.93e+03 |\n",
      "|    total_reward       | 6.28e+04 |\n",
      "|    total_reward_pct   | 6.28     |\n",
      "|    total_trades       | 3544     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 3500     |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 17500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3499     |\n",
      "|    policy_loss        | 58.2     |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 2.05     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.07e+06 |\n",
      "|    total_cost         | 5.71e+03 |\n",
      "|    total_reward       | 7.13e+04 |\n",
      "|    total_reward_pct   | 7.13     |\n",
      "|    total_trades       | 3770     |\n",
      "| time/                 |          |\n",
      "|    fps                | 370      |\n",
      "|    iterations         | 3600     |\n",
      "|    time_elapsed       | 48       |\n",
      "|    total_timesteps    | 18000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.7    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3599     |\n",
      "|    policy_loss        | 57       |\n",
      "|    std                | 1.04     |\n",
      "|    value_loss         | 1.77     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.05e+06  |\n",
      "|    total_cost         | 6.14e+03  |\n",
      "|    total_reward       | 4.66e+04  |\n",
      "|    total_reward_pct   | 4.66      |\n",
      "|    total_trades       | 3830      |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 3700      |\n",
      "|    time_elapsed       | 49        |\n",
      "|    total_timesteps    | 18500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.7     |\n",
      "|    explained_variance | -3.73e+11 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3699      |\n",
      "|    policy_loss        | 30.6      |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.526     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 1.07e+06  |\n",
      "|    total_cost         | 7e+03     |\n",
      "|    total_reward       | 7.44e+04  |\n",
      "|    total_reward_pct   | 7.44      |\n",
      "|    total_trades       | 3911      |\n",
      "| time/                 |           |\n",
      "|    fps                | 371       |\n",
      "|    iterations         | 3800      |\n",
      "|    time_elapsed       | 51        |\n",
      "|    total_timesteps    | 19000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -43.8     |\n",
      "|    explained_variance | -8.31e+11 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 3799      |\n",
      "|    policy_loss        | -19.4     |\n",
      "|    std                | 1.04      |\n",
      "|    value_loss         | 0.403     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 7.68e+03 |\n",
      "|    total_reward       | 4.2e+04  |\n",
      "|    total_reward_pct   | 4.2      |\n",
      "|    total_trades       | 4006     |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 3900     |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 19500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3899     |\n",
      "|    policy_loss        | -46.1    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 1.24     |\n",
      "------------------------------------\n",
      "day: 250, episode: 80\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1085171.69\n",
      "total_reward: 85171.69\n",
      "total_cost: 10002.77\n",
      "total_trades: 4288\n",
      "Sharpe: 0.606\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.09e+06 |\n",
      "|    total_cost         | 1e+04    |\n",
      "|    total_reward       | 8.52e+04 |\n",
      "|    total_reward_pct   | 8.52     |\n",
      "|    total_trades       | 4288     |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 4000     |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 20000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -43.9    |\n",
      "|    explained_variance | 0.543    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 3999     |\n",
      "|    policy_loss        | -17.1    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.199    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.62e+05  |\n",
      "|    total_cost         | 1.09e+04  |\n",
      "|    total_reward       | -3.78e+04 |\n",
      "|    total_reward_pct   | -3.78     |\n",
      "|    total_trades       | 4554      |\n",
      "| time/                 |           |\n",
      "|    fps                | 372       |\n",
      "|    iterations         | 4100      |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 20500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44       |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4099      |\n",
      "|    policy_loss        | 38.1      |\n",
      "|    std                | 1.05      |\n",
      "|    value_loss         | 0.846     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.16e+05 |\n",
      "|    total_cost         | 1.18e+04 |\n",
      "|    total_reward       | -8.4e+04 |\n",
      "|    total_reward_pct   | -8.4     |\n",
      "|    total_trades       | 4381     |\n",
      "| time/                 |          |\n",
      "|    fps                | 372      |\n",
      "|    iterations         | 4200     |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 21000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4199     |\n",
      "|    policy_loss        | -30.1    |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.553    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 1.31e+04 |\n",
      "|    total_reward       | 3.22e+04 |\n",
      "|    total_reward_pct   | 3.22     |\n",
      "|    total_trades       | 4375     |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 4300     |\n",
      "|    time_elapsed       | 57       |\n",
      "|    total_timesteps    | 21500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | -18.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4299     |\n",
      "|    policy_loss        | 28.7     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 0.955    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 1.11e+04 |\n",
      "|    total_reward       | 3.68e+04 |\n",
      "|    total_reward_pct   | 3.68     |\n",
      "|    total_trades       | 4138     |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 4400     |\n",
      "|    time_elapsed       | 59       |\n",
      "|    total_timesteps    | 22000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.1    |\n",
      "|    explained_variance | -127     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4399     |\n",
      "|    policy_loss        | 83.2     |\n",
      "|    std                | 1.05     |\n",
      "|    value_loss         | 3.88     |\n",
      "------------------------------------\n",
      "day: 250, episode: 90\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1011969.35\n",
      "total_reward: 11969.35\n",
      "total_cost: 16167.69\n",
      "total_trades: 4696\n",
      "Sharpe: 0.156\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 1.62e+04 |\n",
      "|    total_reward       | 1.2e+04  |\n",
      "|    total_reward_pct   | 1.2      |\n",
      "|    total_trades       | 4696     |\n",
      "| time/                 |          |\n",
      "|    fps                | 371      |\n",
      "|    iterations         | 4500     |\n",
      "|    time_elapsed       | 60       |\n",
      "|    total_timesteps    | 22500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.2    |\n",
      "|    explained_variance | -1.11    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 4499     |\n",
      "|    policy_loss        | 20.5     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.347    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.69e+05  |\n",
      "|    total_cost         | 1.1e+04   |\n",
      "|    total_reward       | -3.11e+04 |\n",
      "|    total_reward_pct   | -3.11     |\n",
      "|    total_trades       | 4269      |\n",
      "| time/                 |           |\n",
      "|    fps                | 370       |\n",
      "|    iterations         | 4600      |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 23000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -3.4      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4599      |\n",
      "|    policy_loss        | -54.1     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 1.78      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.56e+05  |\n",
      "|    total_cost         | 6.84e+03  |\n",
      "|    total_reward       | -4.37e+04 |\n",
      "|    total_reward_pct   | -4.37     |\n",
      "|    total_trades       | 4024      |\n",
      "| time/                 |           |\n",
      "|    fps                | 369       |\n",
      "|    iterations         | 4700      |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 23500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -3.44     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4699      |\n",
      "|    policy_loss        | -36.1     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.81      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.46e+05  |\n",
      "|    total_cost         | 8.2e+03   |\n",
      "|    total_reward       | -5.36e+04 |\n",
      "|    total_reward_pct   | -5.36     |\n",
      "|    total_trades       | 4341      |\n",
      "| time/                 |           |\n",
      "|    fps                | 368       |\n",
      "|    iterations         | 4800      |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 24000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | -9.32     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4799      |\n",
      "|    policy_loss        | 2.57      |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.37      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.13e+05  |\n",
      "|    total_cost         | 7.48e+03  |\n",
      "|    total_reward       | -8.69e+04 |\n",
      "|    total_reward_pct   | -8.69     |\n",
      "|    total_trades       | 4459      |\n",
      "| time/                 |           |\n",
      "|    fps                | 368       |\n",
      "|    iterations         | 4900      |\n",
      "|    time_elapsed       | 66        |\n",
      "|    total_timesteps    | 24500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.2     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4899      |\n",
      "|    policy_loss        | -13.1     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.634     |\n",
      "-------------------------------------\n",
      "day: 250, episode: 100\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 947525.87\n",
      "total_reward: -52474.13\n",
      "total_cost: 5836.11\n",
      "total_trades: 4020\n",
      "Sharpe: -0.239\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.48e+05  |\n",
      "|    total_cost         | 5.84e+03  |\n",
      "|    total_reward       | -5.25e+04 |\n",
      "|    total_reward_pct   | -5.25     |\n",
      "|    total_trades       | 4020      |\n",
      "| time/                 |           |\n",
      "|    fps                | 367       |\n",
      "|    iterations         | 5000      |\n",
      "|    time_elapsed       | 67        |\n",
      "|    total_timesteps    | 25000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.3     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 4999      |\n",
      "|    policy_loss        | -66.3     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 2.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 4.94e+03 |\n",
      "|    total_reward       | 3.91e+03 |\n",
      "|    total_reward_pct   | 0.391    |\n",
      "|    total_trades       | 3815     |\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 5100     |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 25500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5099     |\n",
      "|    policy_loss        | 13.1     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 1.43     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 4.07e+03 |\n",
      "|    total_reward       | 6.07e+03 |\n",
      "|    total_reward_pct   | 0.607    |\n",
      "|    total_trades       | 3760     |\n",
      "| time/                 |          |\n",
      "|    fps                | 367      |\n",
      "|    iterations         | 5200     |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 26000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.3    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5199     |\n",
      "|    policy_loss        | 86.6     |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 4.61     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1e+06    |\n",
      "|    total_cost         | 4.46e+03 |\n",
      "|    total_reward       | 4.81e+03 |\n",
      "|    total_reward_pct   | 0.481    |\n",
      "|    total_trades       | 3603     |\n",
      "| time/                 |          |\n",
      "|    fps                | 366      |\n",
      "|    iterations         | 5300     |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 26500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5299     |\n",
      "|    policy_loss        | 5.3      |\n",
      "|    std                | 1.06     |\n",
      "|    value_loss         | 0.263    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.96e+05  |\n",
      "|    total_cost         | 4.15e+03  |\n",
      "|    total_reward       | -3.94e+03 |\n",
      "|    total_reward_pct   | -0.394    |\n",
      "|    total_trades       | 3357      |\n",
      "| time/                 |           |\n",
      "|    fps                | 366       |\n",
      "|    iterations         | 5400      |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 27000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.4     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 5399      |\n",
      "|    policy_loss        | -13.7     |\n",
      "|    std                | 1.06      |\n",
      "|    value_loss         | 0.359     |\n",
      "-------------------------------------\n",
      "day: 250, episode: 110\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1007178.15\n",
      "total_reward: 7178.15\n",
      "total_cost: 4939.13\n",
      "total_trades: 3542\n",
      "Sharpe: 0.129\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 4.94e+03 |\n",
      "|    total_reward       | 7.18e+03 |\n",
      "|    total_reward_pct   | 0.718    |\n",
      "|    total_trades       | 3542     |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 5500     |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 27500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.4    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5499     |\n",
      "|    policy_loss        | 58.4     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.74     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 4.31e+03 |\n",
      "|    total_reward       | 1.2e+04  |\n",
      "|    total_reward_pct   | 1.2      |\n",
      "|    total_trades       | 3358     |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 5600     |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 28000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.5    |\n",
      "|    explained_variance | -0.00399 |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5599     |\n",
      "|    policy_loss        | 12.6     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.177    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+06 |\n",
      "|    total_cost         | 4.9e+03  |\n",
      "|    total_reward       | 2.09e+04 |\n",
      "|    total_reward_pct   | 2.09     |\n",
      "|    total_trades       | 3139     |\n",
      "| time/                 |          |\n",
      "|    fps                | 365      |\n",
      "|    iterations         | 5700     |\n",
      "|    time_elapsed       | 78       |\n",
      "|    total_timesteps    | 28500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | -107     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | 30.8     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.54     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 5.23e+03 |\n",
      "|    total_reward       | 3.27e+04 |\n",
      "|    total_reward_pct   | 3.27     |\n",
      "|    total_trades       | 3413     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 5800     |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 29000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5799     |\n",
      "|    policy_loss        | 54.7     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.91     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.05e+06 |\n",
      "|    total_cost         | 4.95e+03 |\n",
      "|    total_reward       | 5.2e+04  |\n",
      "|    total_reward_pct   | 5.2      |\n",
      "|    total_trades       | 3556     |\n",
      "| time/                 |          |\n",
      "|    fps                | 364      |\n",
      "|    iterations         | 5900     |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 29500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5899     |\n",
      "|    policy_loss        | 37.5     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.956    |\n",
      "------------------------------------\n",
      "day: 250, episode: 120\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1042395.31\n",
      "total_reward: 42395.31\n",
      "total_cost: 4258.15\n",
      "total_trades: 3450\n",
      "Sharpe: 0.334\n",
      "=================================\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.04e+06 |\n",
      "|    total_cost         | 4.26e+03 |\n",
      "|    total_reward       | 4.24e+04 |\n",
      "|    total_reward_pct   | 4.24     |\n",
      "|    total_trades       | 3450     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 6000     |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 30000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | -0.211   |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 5999     |\n",
      "|    policy_loss        | -30.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.63     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 4.57e+03 |\n",
      "|    total_reward       | 1.49e+04 |\n",
      "|    total_reward_pct   | 1.49     |\n",
      "|    total_trades       | 3436     |\n",
      "| time/                 |          |\n",
      "|    fps                | 363      |\n",
      "|    iterations         | 6100     |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 30500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.6    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6099     |\n",
      "|    policy_loss        | 26.7     |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.392    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.97e+05 |\n",
      "|    total_cost         | 4e+03    |\n",
      "|    total_reward       | -3.2e+03 |\n",
      "|    total_reward_pct   | -0.32    |\n",
      "|    total_trades       | 3534     |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 6200     |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 31000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6199     |\n",
      "|    policy_loss        | -13.1    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 0.127    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.03e+06 |\n",
      "|    total_cost         | 4.16e+03 |\n",
      "|    total_reward       | 3.05e+04 |\n",
      "|    total_reward_pct   | 3.05     |\n",
      "|    total_trades       | 3626     |\n",
      "| time/                 |          |\n",
      "|    fps                | 362      |\n",
      "|    iterations         | 6300     |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 31500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6299     |\n",
      "|    policy_loss        | 26.6     |\n",
      "|    std                | 1.08     |\n",
      "|    value_loss         | 0.474    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.02e+06 |\n",
      "|    total_cost         | 4.35e+03 |\n",
      "|    total_reward       | 2.47e+04 |\n",
      "|    total_reward_pct   | 2.47     |\n",
      "|    total_trades       | 3534     |\n",
      "| time/                 |          |\n",
      "|    fps                | 361      |\n",
      "|    iterations         | 6400     |\n",
      "|    time_elapsed       | 88       |\n",
      "|    total_timesteps    | 32000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -44.7    |\n",
      "|    explained_variance | -1.64    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 6399     |\n",
      "|    policy_loss        | -42.2    |\n",
      "|    std                | 1.07     |\n",
      "|    value_loss         | 1.25     |\n",
      "------------------------------------\n",
      "day: 250, episode: 130\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 978621.33\n",
      "total_reward: -21378.67\n",
      "total_cost: 3422.68\n",
      "total_trades: 3305\n",
      "Sharpe: -0.038\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.79e+05  |\n",
      "|    total_cost         | 3.42e+03  |\n",
      "|    total_reward       | -2.14e+04 |\n",
      "|    total_reward_pct   | -2.14     |\n",
      "|    total_trades       | 3305      |\n",
      "| time/                 |           |\n",
      "|    fps                | 361       |\n",
      "|    iterations         | 6500      |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 32500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | 0.168     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6499      |\n",
      "|    policy_loss        | -44       |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.952     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.6e+05   |\n",
      "|    total_cost         | 3.97e+03  |\n",
      "|    total_reward       | -4.04e+04 |\n",
      "|    total_reward_pct   | -4.04     |\n",
      "|    total_trades       | 3395      |\n",
      "| time/                 |           |\n",
      "|    fps                | 360       |\n",
      "|    iterations         | 6600      |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 33000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | -203      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6599      |\n",
      "|    policy_loss        | -30.5     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.641     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.2e+05   |\n",
      "|    total_cost         | 3.77e+03  |\n",
      "|    total_reward       | -7.99e+04 |\n",
      "|    total_reward_pct   | -7.99     |\n",
      "|    total_trades       | 3350      |\n",
      "| time/                 |           |\n",
      "|    fps                | 359       |\n",
      "|    iterations         | 6700      |\n",
      "|    time_elapsed       | 93        |\n",
      "|    total_timesteps    | 33500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.7     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6699      |\n",
      "|    policy_loss        | -30.7     |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 0.593     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.74e+05  |\n",
      "|    total_cost         | 3.67e+03  |\n",
      "|    total_reward       | -1.26e+05 |\n",
      "|    total_reward_pct   | -12.6     |\n",
      "|    total_trades       | 3516      |\n",
      "| time/                 |           |\n",
      "|    fps                | 359       |\n",
      "|    iterations         | 6800      |\n",
      "|    time_elapsed       | 94        |\n",
      "|    total_timesteps    | 34000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.8     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6799      |\n",
      "|    policy_loss        | 50.7      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 2.25      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.54e+05  |\n",
      "|    total_cost         | 3.89e+03  |\n",
      "|    total_reward       | -1.46e+05 |\n",
      "|    total_reward_pct   | -14.6     |\n",
      "|    total_trades       | 3486      |\n",
      "| time/                 |           |\n",
      "|    fps                | 359       |\n",
      "|    iterations         | 6900      |\n",
      "|    time_elapsed       | 96        |\n",
      "|    total_timesteps    | 34500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | -16.3     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6899      |\n",
      "|    policy_loss        | 80.3      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 3.42      |\n",
      "-------------------------------------\n",
      "day: 250, episode: 140\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 924861.97\n",
      "total_reward: -75138.03\n",
      "total_cost: 4212.25\n",
      "total_trades: 3521\n",
      "Sharpe: -0.339\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.25e+05  |\n",
      "|    total_cost         | 4.21e+03  |\n",
      "|    total_reward       | -7.51e+04 |\n",
      "|    total_reward_pct   | -7.51     |\n",
      "|    total_trades       | 3521      |\n",
      "| time/                 |           |\n",
      "|    fps                | 358       |\n",
      "|    iterations         | 7000      |\n",
      "|    time_elapsed       | 97        |\n",
      "|    total_timesteps    | 35000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -44.9     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 6999      |\n",
      "|    policy_loss        | 29.2      |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.14      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.31e+05  |\n",
      "|    total_cost         | 4.07e+03  |\n",
      "|    total_reward       | -6.91e+04 |\n",
      "|    total_reward_pct   | -6.91     |\n",
      "|    total_trades       | 3730      |\n",
      "| time/                 |           |\n",
      "|    fps                | 358       |\n",
      "|    iterations         | 7100      |\n",
      "|    time_elapsed       | 98        |\n",
      "|    total_timesteps    | 35500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | -2.66e+06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7099      |\n",
      "|    policy_loss        | 21        |\n",
      "|    std                | 1.08      |\n",
      "|    value_loss         | 1.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.27e+05  |\n",
      "|    total_cost         | 4.11e+03  |\n",
      "|    total_reward       | -7.31e+04 |\n",
      "|    total_reward_pct   | -7.31     |\n",
      "|    total_trades       | 3737      |\n",
      "| time/                 |           |\n",
      "|    fps                | 358       |\n",
      "|    iterations         | 7200      |\n",
      "|    time_elapsed       | 100       |\n",
      "|    total_timesteps    | 36000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45       |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7199      |\n",
      "|    policy_loss        | 20.3      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 1.86      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.07e+05  |\n",
      "|    total_cost         | 5.99e+03  |\n",
      "|    total_reward       | -9.26e+04 |\n",
      "|    total_reward_pct   | -9.26     |\n",
      "|    total_trades       | 3801      |\n",
      "| time/                 |           |\n",
      "|    fps                | 358       |\n",
      "|    iterations         | 7300      |\n",
      "|    time_elapsed       | 101       |\n",
      "|    total_timesteps    | 36500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | -30.4     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7299      |\n",
      "|    policy_loss        | -90.3     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 4.63      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.81e+05  |\n",
      "|    total_cost         | 4.71e+03  |\n",
      "|    total_reward       | -1.19e+05 |\n",
      "|    total_reward_pct   | -11.9     |\n",
      "|    total_trades       | 3550      |\n",
      "| time/                 |           |\n",
      "|    fps                | 358       |\n",
      "|    iterations         | 7400      |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 37000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.1     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7399      |\n",
      "|    policy_loss        | 10.6      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.157     |\n",
      "-------------------------------------\n",
      "day: 250, episode: 150\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 934702.75\n",
      "total_reward: -65297.25\n",
      "total_cost: 4062.60\n",
      "total_trades: 3499\n",
      "Sharpe: -0.287\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.35e+05  |\n",
      "|    total_cost         | 4.06e+03  |\n",
      "|    total_reward       | -6.53e+04 |\n",
      "|    total_reward_pct   | -6.53     |\n",
      "|    total_trades       | 3499      |\n",
      "| time/                 |           |\n",
      "|    fps                | 357       |\n",
      "|    iterations         | 7500      |\n",
      "|    time_elapsed       | 104       |\n",
      "|    total_timesteps    | 37500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7499      |\n",
      "|    policy_loss        | 34        |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.611     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.33e+05  |\n",
      "|    total_cost         | 4.05e+03  |\n",
      "|    total_reward       | -6.7e+04  |\n",
      "|    total_reward_pct   | -6.7      |\n",
      "|    total_trades       | 3400      |\n",
      "| time/                 |           |\n",
      "|    fps                | 357       |\n",
      "|    iterations         | 7600      |\n",
      "|    time_elapsed       | 106       |\n",
      "|    total_timesteps    | 38000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -1.31e+08 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7599      |\n",
      "|    policy_loss        | -3.66     |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 0.0452    |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.5e+05   |\n",
      "|    total_cost         | 3.78e+03  |\n",
      "|    total_reward       | -5.01e+04 |\n",
      "|    total_reward_pct   | -5.01     |\n",
      "|    total_trades       | 3294      |\n",
      "| time/                 |           |\n",
      "|    fps                | 357       |\n",
      "|    iterations         | 7700      |\n",
      "|    time_elapsed       | 107       |\n",
      "|    total_timesteps    | 38500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7699      |\n",
      "|    policy_loss        | 43        |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 2.39      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.47e+05  |\n",
      "|    total_cost         | 3.32e+03  |\n",
      "|    total_reward       | -5.29e+04 |\n",
      "|    total_reward_pct   | -5.29     |\n",
      "|    total_trades       | 3352      |\n",
      "| time/                 |           |\n",
      "|    fps                | 357       |\n",
      "|    iterations         | 7800      |\n",
      "|    time_elapsed       | 109       |\n",
      "|    total_timesteps    | 39000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.2     |\n",
      "|    explained_variance | -23       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7799      |\n",
      "|    policy_loss        | 95.4      |\n",
      "|    std                | 1.09      |\n",
      "|    value_loss         | 6.18      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.39e+05  |\n",
      "|    total_cost         | 3.41e+03  |\n",
      "|    total_reward       | -6.14e+04 |\n",
      "|    total_reward_pct   | -6.14     |\n",
      "|    total_trades       | 3418      |\n",
      "| time/                 |           |\n",
      "|    fps                | 356       |\n",
      "|    iterations         | 7900      |\n",
      "|    time_elapsed       | 110       |\n",
      "|    total_timesteps    | 39500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | -5.96     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7899      |\n",
      "|    policy_loss        | 111       |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 6.06      |\n",
      "-------------------------------------\n",
      "day: 250, episode: 160\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 961146.66\n",
      "total_reward: -38853.34\n",
      "total_cost: 3471.12\n",
      "total_trades: 3475\n",
      "Sharpe: -0.129\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.61e+05  |\n",
      "|    total_cost         | 3.47e+03  |\n",
      "|    total_reward       | -3.89e+04 |\n",
      "|    total_reward_pct   | -3.89     |\n",
      "|    total_trades       | 3475      |\n",
      "| time/                 |           |\n",
      "|    fps                | 356       |\n",
      "|    iterations         | 8000      |\n",
      "|    time_elapsed       | 112       |\n",
      "|    total_timesteps    | 40000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 7999      |\n",
      "|    policy_loss        | 7.24      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.37      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.42e+05 |\n",
      "|    total_cost         | 3.06e+03 |\n",
      "|    total_reward       | -5.8e+04 |\n",
      "|    total_reward_pct   | -5.8     |\n",
      "|    total_trades       | 3355     |\n",
      "| time/                 |          |\n",
      "|    fps                | 356      |\n",
      "|    iterations         | 8100     |\n",
      "|    time_elapsed       | 113      |\n",
      "|    total_timesteps    | 40500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -45.3    |\n",
      "|    explained_variance | -4.4     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 8099     |\n",
      "|    policy_loss        | -22.9    |\n",
      "|    std                | 1.1      |\n",
      "|    value_loss         | 1.02     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.33e+05  |\n",
      "|    total_cost         | 2.96e+03  |\n",
      "|    total_reward       | -6.71e+04 |\n",
      "|    total_reward_pct   | -6.71     |\n",
      "|    total_trades       | 3352      |\n",
      "| time/                 |           |\n",
      "|    fps                | 356       |\n",
      "|    iterations         | 8200      |\n",
      "|    time_elapsed       | 115       |\n",
      "|    total_timesteps    | 41000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | -3.99     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8199      |\n",
      "|    policy_loss        | -52.1     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.68      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.43e+05  |\n",
      "|    total_cost         | 3.32e+03  |\n",
      "|    total_reward       | -5.68e+04 |\n",
      "|    total_reward_pct   | -5.68     |\n",
      "|    total_trades       | 3320      |\n",
      "| time/                 |           |\n",
      "|    fps                | 355       |\n",
      "|    iterations         | 8300      |\n",
      "|    time_elapsed       | 116       |\n",
      "|    total_timesteps    | 41500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.3     |\n",
      "|    explained_variance | -4.19     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8299      |\n",
      "|    policy_loss        | -4.91     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.401     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.47e+05  |\n",
      "|    total_cost         | 3.42e+03  |\n",
      "|    total_reward       | -5.31e+04 |\n",
      "|    total_reward_pct   | -5.31     |\n",
      "|    total_trades       | 3315      |\n",
      "| time/                 |           |\n",
      "|    fps                | 355       |\n",
      "|    iterations         | 8400      |\n",
      "|    time_elapsed       | 118       |\n",
      "|    total_timesteps    | 42000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -111      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8399      |\n",
      "|    policy_loss        | -34       |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.84      |\n",
      "-------------------------------------\n",
      "day: 250, episode: 170\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 934544.83\n",
      "total_reward: -65455.17\n",
      "total_cost: 2846.17\n",
      "total_trades: 3302\n",
      "Sharpe: -0.293\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.35e+05  |\n",
      "|    total_cost         | 2.85e+03  |\n",
      "|    total_reward       | -6.55e+04 |\n",
      "|    total_reward_pct   | -6.55     |\n",
      "|    total_trades       | 3302      |\n",
      "| time/                 |           |\n",
      "|    fps                | 355       |\n",
      "|    iterations         | 8500      |\n",
      "|    time_elapsed       | 119       |\n",
      "|    total_timesteps    | 42500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | -5.05e+13 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8499      |\n",
      "|    policy_loss        | 37.3      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.47      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.21e+05  |\n",
      "|    total_cost         | 2.84e+03  |\n",
      "|    total_reward       | -7.87e+04 |\n",
      "|    total_reward_pct   | -7.87     |\n",
      "|    total_trades       | 3342      |\n",
      "| time/                 |           |\n",
      "|    fps                | 355       |\n",
      "|    iterations         | 8600      |\n",
      "|    time_elapsed       | 121       |\n",
      "|    total_timesteps    | 43000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.4     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8599      |\n",
      "|    policy_loss        | 96.6      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 5.22      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.45e+05  |\n",
      "|    total_cost         | 3.2e+03   |\n",
      "|    total_reward       | -5.48e+04 |\n",
      "|    total_reward_pct   | -5.48     |\n",
      "|    total_trades       | 3405      |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 8700      |\n",
      "|    time_elapsed       | 123       |\n",
      "|    total_timesteps    | 43500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8699      |\n",
      "|    policy_loss        | 54.8      |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.89      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.35e+05  |\n",
      "|    total_cost         | 3.24e+03  |\n",
      "|    total_reward       | -6.52e+04 |\n",
      "|    total_reward_pct   | -6.52     |\n",
      "|    total_trades       | 3295      |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 8800      |\n",
      "|    time_elapsed       | 124       |\n",
      "|    total_timesteps    | 44000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8799      |\n",
      "|    policy_loss        | 37.2      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.31e+05  |\n",
      "|    total_cost         | 3.07e+03  |\n",
      "|    total_reward       | -6.86e+04 |\n",
      "|    total_reward_pct   | -6.86     |\n",
      "|    total_trades       | 3393      |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 8900      |\n",
      "|    time_elapsed       | 126       |\n",
      "|    total_timesteps    | 44500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8899      |\n",
      "|    policy_loss        | -0.16     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 0.815     |\n",
      "-------------------------------------\n",
      "day: 250, episode: 180\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 914155.77\n",
      "total_reward: -85844.23\n",
      "total_cost: 3148.52\n",
      "total_trades: 3467\n",
      "Sharpe: -0.399\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.14e+05  |\n",
      "|    total_cost         | 3.15e+03  |\n",
      "|    total_reward       | -8.58e+04 |\n",
      "|    total_reward_pct   | -8.58     |\n",
      "|    total_trades       | 3467      |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 9000      |\n",
      "|    time_elapsed       | 127       |\n",
      "|    total_timesteps    | 45000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | -8.94e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 8999      |\n",
      "|    policy_loss        | -12.2     |\n",
      "|    std                | 1.1       |\n",
      "|    value_loss         | 1.44      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.19e+05  |\n",
      "|    total_cost         | 2.98e+03  |\n",
      "|    total_reward       | -8.12e+04 |\n",
      "|    total_reward_pct   | -8.12     |\n",
      "|    total_trades       | 3557      |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 9100      |\n",
      "|    time_elapsed       | 129       |\n",
      "|    total_timesteps    | 45500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9099      |\n",
      "|    policy_loss        | 89.2      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 5.07      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.59e+05  |\n",
      "|    total_cost         | 3.16e+03  |\n",
      "|    total_reward       | -4.05e+04 |\n",
      "|    total_reward_pct   | -4.05     |\n",
      "|    total_trades       | 3691      |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 9200      |\n",
      "|    time_elapsed       | 130       |\n",
      "|    total_timesteps    | 46000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.6     |\n",
      "|    explained_variance | -3.37     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9199      |\n",
      "|    policy_loss        | 15.6      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.466     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.5e+05   |\n",
      "|    total_cost         | 3.13e+03  |\n",
      "|    total_reward       | -4.99e+04 |\n",
      "|    total_reward_pct   | -4.99     |\n",
      "|    total_trades       | 3769      |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 9300      |\n",
      "|    time_elapsed       | 132       |\n",
      "|    total_timesteps    | 46500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.5     |\n",
      "|    explained_variance | -2.29     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9299      |\n",
      "|    policy_loss        | 50.7      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1.43      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.51e+05  |\n",
      "|    total_cost         | 2.91e+03  |\n",
      "|    total_reward       | -4.92e+04 |\n",
      "|    total_reward_pct   | -4.92     |\n",
      "|    total_trades       | 3675      |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 9400      |\n",
      "|    time_elapsed       | 133       |\n",
      "|    total_timesteps    | 47000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.6     |\n",
      "|    explained_variance | -739      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9399      |\n",
      "|    policy_loss        | -40.8     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 3.15      |\n",
      "-------------------------------------\n",
      "day: 250, episode: 190\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 960081.65\n",
      "total_reward: -39918.35\n",
      "total_cost: 2844.25\n",
      "total_trades: 3679\n",
      "Sharpe: -0.133\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.6e+05   |\n",
      "|    total_cost         | 2.84e+03  |\n",
      "|    total_reward       | -3.99e+04 |\n",
      "|    total_reward_pct   | -3.99     |\n",
      "|    total_trades       | 3679      |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 9500      |\n",
      "|    time_elapsed       | 134       |\n",
      "|    total_timesteps    | 47500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.6     |\n",
      "|    explained_variance | -4.71e+03 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9499      |\n",
      "|    policy_loss        | -147      |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 12.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.6e+05   |\n",
      "|    total_cost         | 2.96e+03  |\n",
      "|    total_reward       | -4.03e+04 |\n",
      "|    total_reward_pct   | -4.03     |\n",
      "|    total_trades       | 3692      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 9600      |\n",
      "|    time_elapsed       | 136       |\n",
      "|    total_timesteps    | 48000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.7     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9599      |\n",
      "|    policy_loss        | -16.3     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 0.267     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.64e+05  |\n",
      "|    total_cost         | 2.69e+03  |\n",
      "|    total_reward       | -3.57e+04 |\n",
      "|    total_reward_pct   | -3.57     |\n",
      "|    total_trades       | 3728      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 9700      |\n",
      "|    time_elapsed       | 137       |\n",
      "|    total_timesteps    | 48500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.8     |\n",
      "|    explained_variance | -191      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9699      |\n",
      "|    policy_loss        | -52.6     |\n",
      "|    std                | 1.11      |\n",
      "|    value_loss         | 1.64      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.58e+05  |\n",
      "|    total_cost         | 2.81e+03  |\n",
      "|    total_reward       | -4.17e+04 |\n",
      "|    total_reward_pct   | -4.17     |\n",
      "|    total_trades       | 3794      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 9800      |\n",
      "|    time_elapsed       | 139       |\n",
      "|    total_timesteps    | 49000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.8     |\n",
      "|    explained_variance | -64.9     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9799      |\n",
      "|    policy_loss        | -36.4     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 1.36      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.66e+05  |\n",
      "|    total_cost         | 2.61e+03  |\n",
      "|    total_reward       | -3.39e+04 |\n",
      "|    total_reward_pct   | -3.39     |\n",
      "|    total_trades       | 3732      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 9900      |\n",
      "|    time_elapsed       | 140       |\n",
      "|    total_timesteps    | 49500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.8     |\n",
      "|    explained_variance | -3.26     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9899      |\n",
      "|    policy_loss        | -30.1     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.792     |\n",
      "-------------------------------------\n",
      "day: 250, episode: 200\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 917179.12\n",
      "total_reward: -82820.88\n",
      "total_cost: 3180.53\n",
      "total_trades: 3614\n",
      "Sharpe: -0.429\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.17e+05  |\n",
      "|    total_cost         | 3.18e+03  |\n",
      "|    total_reward       | -8.28e+04 |\n",
      "|    total_reward_pct   | -8.28     |\n",
      "|    total_trades       | 3614      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 10000     |\n",
      "|    time_elapsed       | 142       |\n",
      "|    total_timesteps    | 50000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -45.9     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 9999      |\n",
      "|    policy_loss        | 75.4      |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 3.22      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.88e+05  |\n",
      "|    total_cost         | 3.37e+03  |\n",
      "|    total_reward       | -1.16e+04 |\n",
      "|    total_reward_pct   | -1.16     |\n",
      "|    total_trades       | 3843      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 10100     |\n",
      "|    time_elapsed       | 143       |\n",
      "|    total_timesteps    | 50500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46       |\n",
      "|    explained_variance | -0.975    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10099     |\n",
      "|    policy_loss        | -33.9     |\n",
      "|    std                | 1.12      |\n",
      "|    value_loss         | 0.644     |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 2.66e+03 |\n",
      "|    total_reward       | 8.31e+03 |\n",
      "|    total_reward_pct   | 0.831    |\n",
      "|    total_trades       | 3741     |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 10200    |\n",
      "|    time_elapsed       | 145      |\n",
      "|    total_timesteps    | 51000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46      |\n",
      "|    explained_variance | -18.8    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10199    |\n",
      "|    policy_loss        | -10.3    |\n",
      "|    std                | 1.12     |\n",
      "|    value_loss         | 1.97     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.86e+05  |\n",
      "|    total_cost         | 2.54e+03  |\n",
      "|    total_reward       | -1.4e+04  |\n",
      "|    total_reward_pct   | -1.4      |\n",
      "|    total_trades       | 3847      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 10300     |\n",
      "|    time_elapsed       | 146       |\n",
      "|    total_timesteps    | 51500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.1     |\n",
      "|    explained_variance | -2.33e+13 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10299     |\n",
      "|    policy_loss        | -108      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 7.86      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.71e+05  |\n",
      "|    total_cost         | 2.93e+03  |\n",
      "|    total_reward       | -2.86e+04 |\n",
      "|    total_reward_pct   | -2.86     |\n",
      "|    total_trades       | 3779      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 10400     |\n",
      "|    time_elapsed       | 147       |\n",
      "|    total_timesteps    | 52000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.2     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10399     |\n",
      "|    policy_loss        | 26.1      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 1.77      |\n",
      "-------------------------------------\n",
      "day: 250, episode: 210\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 952655.32\n",
      "total_reward: -47344.68\n",
      "total_cost: 2868.73\n",
      "total_trades: 3806\n",
      "Sharpe: -0.193\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.53e+05  |\n",
      "|    total_cost         | 2.87e+03  |\n",
      "|    total_reward       | -4.73e+04 |\n",
      "|    total_reward_pct   | -4.73     |\n",
      "|    total_trades       | 3806      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 10500     |\n",
      "|    time_elapsed       | 149       |\n",
      "|    total_timesteps    | 52500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.2     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10499     |\n",
      "|    policy_loss        | 39.6      |\n",
      "|    std                | 1.13      |\n",
      "|    value_loss         | 1.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 1.01e+06 |\n",
      "|    total_cost         | 3.27e+03 |\n",
      "|    total_reward       | 6.91e+03 |\n",
      "|    total_reward_pct   | 0.691    |\n",
      "|    total_trades       | 3892     |\n",
      "| time/                 |          |\n",
      "|    fps                | 351      |\n",
      "|    iterations         | 10600    |\n",
      "|    time_elapsed       | 150      |\n",
      "|    total_timesteps    | 53000    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -46.3    |\n",
      "|    explained_variance | -14.7    |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 10599    |\n",
      "|    policy_loss        | -28.4    |\n",
      "|    std                | 1.14     |\n",
      "|    value_loss         | 1.37     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.35e+05  |\n",
      "|    total_cost         | 2.65e+03  |\n",
      "|    total_reward       | -6.51e+04 |\n",
      "|    total_reward_pct   | -6.51     |\n",
      "|    total_trades       | 3811      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 10700     |\n",
      "|    time_elapsed       | 152       |\n",
      "|    total_timesteps    | 53500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | -14.8     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10699     |\n",
      "|    policy_loss        | 101       |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 6.64      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.66e+05  |\n",
      "|    total_cost         | 2.81e+03  |\n",
      "|    total_reward       | -3.43e+04 |\n",
      "|    total_reward_pct   | -3.43     |\n",
      "|    total_trades       | 3803      |\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 10800     |\n",
      "|    time_elapsed       | 153       |\n",
      "|    total_timesteps    | 54000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.5     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10799     |\n",
      "|    policy_loss        | 102       |\n",
      "|    std                | 1.14      |\n",
      "|    value_loss         | 7.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.47e+05  |\n",
      "|    total_cost         | 2.68e+03  |\n",
      "|    total_reward       | -5.27e+04 |\n",
      "|    total_reward_pct   | -5.27     |\n",
      "|    total_trades       | 3828      |\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 10900     |\n",
      "|    time_elapsed       | 155       |\n",
      "|    total_timesteps    | 54500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10899     |\n",
      "|    policy_loss        | 32.7      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 3.15      |\n",
      "-------------------------------------\n",
      "day: 250, episode: 220\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 957642.44\n",
      "total_reward: -42357.56\n",
      "total_cost: 3099.21\n",
      "total_trades: 3948\n",
      "Sharpe: -0.176\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.58e+05  |\n",
      "|    total_cost         | 3.1e+03   |\n",
      "|    total_reward       | -4.24e+04 |\n",
      "|    total_reward_pct   | -4.24     |\n",
      "|    total_trades       | 3948      |\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 11000     |\n",
      "|    time_elapsed       | 156       |\n",
      "|    total_timesteps    | 55000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | -41.3     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 10999     |\n",
      "|    policy_loss        | -214      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 29.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.89e+05  |\n",
      "|    total_cost         | 3e+03     |\n",
      "|    total_reward       | -1.07e+04 |\n",
      "|    total_reward_pct   | -1.07     |\n",
      "|    total_trades       | 3795      |\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 11100     |\n",
      "|    time_elapsed       | 158       |\n",
      "|    total_timesteps    | 55500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.6     |\n",
      "|    explained_variance | -49.1     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11099     |\n",
      "|    policy_loss        | -108      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 12.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.5e+05   |\n",
      "|    total_cost         | 3.03e+03  |\n",
      "|    total_reward       | -5.03e+04 |\n",
      "|    total_reward_pct   | -5.03     |\n",
      "|    total_trades       | 3818      |\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 11200     |\n",
      "|    time_elapsed       | 159       |\n",
      "|    total_timesteps    | 56000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.7     |\n",
      "|    explained_variance | -2.61     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11199     |\n",
      "|    policy_loss        | -123      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 8.12      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.3e+05   |\n",
      "|    total_cost         | 2.87e+03  |\n",
      "|    total_reward       | -7.04e+04 |\n",
      "|    total_reward_pct   | -7.04     |\n",
      "|    total_trades       | 3833      |\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 11300     |\n",
      "|    time_elapsed       | 161       |\n",
      "|    total_timesteps    | 56500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11299     |\n",
      "|    policy_loss        | -2.16     |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 0.259     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.03e+05  |\n",
      "|    total_cost         | 2.49e+03  |\n",
      "|    total_reward       | -9.66e+04 |\n",
      "|    total_reward_pct   | -9.66     |\n",
      "|    total_trades       | 3681      |\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 11400     |\n",
      "|    time_elapsed       | 163       |\n",
      "|    total_timesteps    | 57000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.8     |\n",
      "|    explained_variance | -53.6     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11399     |\n",
      "|    policy_loss        | 36.8      |\n",
      "|    std                | 1.15      |\n",
      "|    value_loss         | 1.04      |\n",
      "-------------------------------------\n",
      "day: 250, episode: 230\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 992074.19\n",
      "total_reward: -7925.81\n",
      "total_cost: 3050.38\n",
      "total_trades: 3599\n",
      "Sharpe: 0.034\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.92e+05  |\n",
      "|    total_cost         | 3.05e+03  |\n",
      "|    total_reward       | -7.93e+03 |\n",
      "|    total_reward_pct   | -0.793    |\n",
      "|    total_trades       | 3599      |\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 11500     |\n",
      "|    time_elapsed       | 164       |\n",
      "|    total_timesteps    | 57500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.9     |\n",
      "|    explained_variance | 0.593     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11499     |\n",
      "|    policy_loss        | 14        |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.804     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.67e+05  |\n",
      "|    total_cost         | 3e+03     |\n",
      "|    total_reward       | -3.28e+04 |\n",
      "|    total_reward_pct   | -3.28     |\n",
      "|    total_trades       | 3582      |\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 11600     |\n",
      "|    time_elapsed       | 165       |\n",
      "|    total_timesteps    | 58000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -46.9     |\n",
      "|    explained_variance | -0.172    |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11599     |\n",
      "|    policy_loss        | -96.4     |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 4.58      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.66e+05  |\n",
      "|    total_cost         | 3.02e+03  |\n",
      "|    total_reward       | -3.37e+04 |\n",
      "|    total_reward_pct   | -3.37     |\n",
      "|    total_trades       | 3536      |\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 11700     |\n",
      "|    time_elapsed       | 167       |\n",
      "|    total_timesteps    | 58500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47       |\n",
      "|    explained_variance | 0.172     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11699     |\n",
      "|    policy_loss        | -90       |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 5.11      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.78e+05  |\n",
      "|    total_cost         | 2.43e+03  |\n",
      "|    total_reward       | -1.22e+05 |\n",
      "|    total_reward_pct   | -12.2     |\n",
      "|    total_trades       | 3592      |\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 11800     |\n",
      "|    time_elapsed       | 168       |\n",
      "|    total_timesteps    | 59000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47       |\n",
      "|    explained_variance | 0.839     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11799     |\n",
      "|    policy_loss        | -99.4     |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 4.29      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.43e+05 |\n",
      "|    total_cost         | 2.57e+03 |\n",
      "|    total_reward       | -5.7e+04 |\n",
      "|    total_reward_pct   | -5.7     |\n",
      "|    total_trades       | 3576     |\n",
      "| time/                 |          |\n",
      "|    fps                | 349      |\n",
      "|    iterations         | 11900    |\n",
      "|    time_elapsed       | 170      |\n",
      "|    total_timesteps    | 59500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.1    |\n",
      "|    explained_variance | nan      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 11899    |\n",
      "|    policy_loss        | 0.867    |\n",
      "|    std                | 1.16     |\n",
      "|    value_loss         | 0.0148   |\n",
      "------------------------------------\n",
      "day: 250, episode: 240\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 892728.23\n",
      "total_reward: -107271.77\n",
      "total_cost: 2441.29\n",
      "total_trades: 3556\n",
      "Sharpe: -0.562\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.93e+05  |\n",
      "|    total_cost         | 2.44e+03  |\n",
      "|    total_reward       | -1.07e+05 |\n",
      "|    total_reward_pct   | -10.7     |\n",
      "|    total_trades       | 3556      |\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 12000     |\n",
      "|    time_elapsed       | 171       |\n",
      "|    total_timesteps    | 60000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 11999     |\n",
      "|    policy_loss        | -1        |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 0.00554   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.88e+05  |\n",
      "|    total_cost         | 2.52e+03  |\n",
      "|    total_reward       | -1.12e+05 |\n",
      "|    total_reward_pct   | -11.2     |\n",
      "|    total_trades       | 3534      |\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 12100     |\n",
      "|    time_elapsed       | 173       |\n",
      "|    total_timesteps    | 60500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | 0.95      |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12099     |\n",
      "|    policy_loss        | 10.2      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.155     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.96e+05  |\n",
      "|    total_cost         | 3.11e+03  |\n",
      "|    total_reward       | -1.04e+05 |\n",
      "|    total_reward_pct   | -10.4     |\n",
      "|    total_trades       | 3647      |\n",
      "| time/                 |           |\n",
      "|    fps                | 349       |\n",
      "|    iterations         | 12200     |\n",
      "|    time_elapsed       | 174       |\n",
      "|    total_timesteps    | 61000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | 0.958     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12199     |\n",
      "|    policy_loss        | 13.4      |\n",
      "|    std                | 1.16      |\n",
      "|    value_loss         | 0.241     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.48e+05  |\n",
      "|    total_cost         | 2.26e+03  |\n",
      "|    total_reward       | -1.52e+05 |\n",
      "|    total_reward_pct   | -15.2     |\n",
      "|    total_trades       | 3665      |\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 12300     |\n",
      "|    time_elapsed       | 175       |\n",
      "|    total_timesteps    | 61500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | -8.38     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12299     |\n",
      "|    policy_loss        | 58.7      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 3.64      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.05e+05  |\n",
      "|    total_cost         | 2.16e+03  |\n",
      "|    total_reward       | -9.53e+04 |\n",
      "|    total_reward_pct   | -9.53     |\n",
      "|    total_trades       | 3774      |\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 12400     |\n",
      "|    time_elapsed       | 177       |\n",
      "|    total_timesteps    | 62000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | -15.2     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12399     |\n",
      "|    policy_loss        | 61.1      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 4.32      |\n",
      "-------------------------------------\n",
      "day: 250, episode: 250\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882046.98\n",
      "total_reward: -117953.02\n",
      "total_cost: 2240.47\n",
      "total_trades: 3808\n",
      "Sharpe: -0.609\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.82e+05  |\n",
      "|    total_cost         | 2.24e+03  |\n",
      "|    total_reward       | -1.18e+05 |\n",
      "|    total_reward_pct   | -11.8     |\n",
      "|    total_trades       | 3808      |\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 12500     |\n",
      "|    time_elapsed       | 178       |\n",
      "|    total_timesteps    | 62500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.1     |\n",
      "|    explained_variance | -28.4     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12499     |\n",
      "|    policy_loss        | -29.4     |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 6.28      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.82e+05  |\n",
      "|    total_cost         | 2.37e+03  |\n",
      "|    total_reward       | -1.18e+05 |\n",
      "|    total_reward_pct   | -11.8     |\n",
      "|    total_trades       | 3805      |\n",
      "| time/                 |           |\n",
      "|    fps                | 350       |\n",
      "|    iterations         | 12600     |\n",
      "|    time_elapsed       | 179       |\n",
      "|    total_timesteps    | 63000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.2     |\n",
      "|    explained_variance | nan       |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12599     |\n",
      "|    policy_loss        | -214      |\n",
      "|    std                | 1.17      |\n",
      "|    value_loss         | 23.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.1e+05  |\n",
      "|    total_cost         | 2.52e+03 |\n",
      "|    total_reward       | -9e+04   |\n",
      "|    total_reward_pct   | -9       |\n",
      "|    total_trades       | 3783     |\n",
      "| time/                 |          |\n",
      "|    fps                | 350      |\n",
      "|    iterations         | 12700    |\n",
      "|    time_elapsed       | 180      |\n",
      "|    total_timesteps    | 63500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.3    |\n",
      "|    explained_variance | -30      |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 12699    |\n",
      "|    policy_loss        | -112     |\n",
      "|    std                | 1.17     |\n",
      "|    value_loss         | 8.28     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.04e+05  |\n",
      "|    total_cost         | 2.24e+03  |\n",
      "|    total_reward       | -9.62e+04 |\n",
      "|    total_reward_pct   | -9.62     |\n",
      "|    total_trades       | 3740      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 12800     |\n",
      "|    time_elapsed       | 182       |\n",
      "|    total_timesteps    | 64000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.3     |\n",
      "|    explained_variance | 0.127     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12799     |\n",
      "|    policy_loss        | -89.2     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 4.36      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.06e+05  |\n",
      "|    total_cost         | 2.52e+03  |\n",
      "|    total_reward       | -9.39e+04 |\n",
      "|    total_reward_pct   | -9.39     |\n",
      "|    total_trades       | 3561      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 12900     |\n",
      "|    time_elapsed       | 183       |\n",
      "|    total_timesteps    | 64500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.4     |\n",
      "|    explained_variance | -17.1     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12899     |\n",
      "|    policy_loss        | -3.96     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 0.771     |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.02e+05  |\n",
      "|    total_cost         | 1.87e+03  |\n",
      "|    total_reward       | -9.81e+04 |\n",
      "|    total_reward_pct   | -9.81     |\n",
      "|    total_trades       | 3613      |\n",
      "| time/                 |           |\n",
      "|    fps                | 351       |\n",
      "|    iterations         | 13000     |\n",
      "|    time_elapsed       | 184       |\n",
      "|    total_timesteps    | 65000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.5     |\n",
      "|    explained_variance | -39.5     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 12999     |\n",
      "|    policy_loss        | -97.5     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 7.42      |\n",
      "-------------------------------------\n",
      "day: 250, episode: 260\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 894674.49\n",
      "total_reward: -105325.51\n",
      "total_cost: 2119.10\n",
      "total_trades: 3627\n",
      "Sharpe: -0.537\n",
      "=================================\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 9.08e+05  |\n",
      "|    total_cost         | 2.23e+03  |\n",
      "|    total_reward       | -9.22e+04 |\n",
      "|    total_reward_pct   | -9.22     |\n",
      "|    total_trades       | 3659      |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 13100     |\n",
      "|    time_elapsed       | 186       |\n",
      "|    total_timesteps    | 65500     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.5     |\n",
      "|    explained_variance | -17.9     |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13099     |\n",
      "|    policy_loss        | -125      |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 7.91      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| environment/          |           |\n",
      "|    portfolio_value    | 8.62e+05  |\n",
      "|    total_cost         | 2.63e+03  |\n",
      "|    total_reward       | -1.38e+05 |\n",
      "|    total_reward_pct   | -13.8     |\n",
      "|    total_trades       | 3741      |\n",
      "| time/                 |           |\n",
      "|    fps                | 352       |\n",
      "|    iterations         | 13200     |\n",
      "|    time_elapsed       | 187       |\n",
      "|    total_timesteps    | 66000     |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -47.5     |\n",
      "|    explained_variance | -7.77e+06 |\n",
      "|    learning_rate      | 0.0007    |\n",
      "|    n_updates          | 13199     |\n",
      "|    policy_loss        | -69.9     |\n",
      "|    std                | 1.18      |\n",
      "|    value_loss         | 3.76      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| environment/          |          |\n",
      "|    portfolio_value    | 9.05e+05 |\n",
      "|    total_cost         | 2.57e+03 |\n",
      "|    total_reward       | -9.5e+04 |\n",
      "|    total_reward_pct   | -9.5     |\n",
      "|    total_trades       | 3799     |\n",
      "| time/                 |          |\n",
      "|    fps                | 352      |\n",
      "|    iterations         | 13300    |\n",
      "|    time_elapsed       | 188      |\n",
      "|    total_timesteps    | 66500    |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -47.6    |\n",
      "|    explained_variance | -7.4     |\n",
      "|    learning_rate      | 0.0007   |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | 96.3     |\n",
      "|    std                | 1.19     |\n",
      "|    value_loss         | 5.7      |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "trained_a2c = agent.train_model(model=model_a2c, \n",
    "                             tb_log_name='a2c',\n",
    "                             total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRiOtrywfAo1"
   },
   "source": [
    "### Model 2: DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2YadjfnLwgt",
    "outputId": "3b2a8f89-0561-4083-a015-fbee11693037"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "model_ddpg = agent.get_model(\"ddpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "tCDa78rqfO_a",
    "outputId": "f651f8be-4c93-4b1e-c88a-7e3a09976693"
   },
   "outputs": [],
   "source": [
    "trained_ddpg = agent.train_model(model=model_ddpg, \n",
    "                             tb_log_name='ddpg',\n",
    "                             total_timesteps=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_gDkU-j-fCmZ"
   },
   "source": [
    "### Model 3: PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y5D5PFUhMzSV",
    "outputId": "2716af5e-06e5-4eab-b071-a506c60a0475"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "PPO_PARAMS = {\n",
    "    \"n_steps\": 2048,\n",
    "    \"ent_coef\": 0.01,\n",
    "    \"learning_rate\": 0.00025,\n",
    "    \"batch_size\": 128,\n",
    "}\n",
    "model_ppo = agent.get_model(\"ppo\",model_kwargs = PPO_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gt8eIQKYM4G3",
    "outputId": "1016cc05-58b6-45dc-c871-a322f1c3dc89"
   },
   "outputs": [],
   "source": [
    "trained_ppo = agent.train_model(model=model_ppo, \n",
    "                             tb_log_name='ppo',\n",
    "                             total_timesteps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Zpv4S0-fDBv"
   },
   "source": [
    "### Model 4: TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JSAHhV4Xc-bh",
    "outputId": "e531db14-aab4-47d1-cc15-02c893ec66c9"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "TD3_PARAMS = {\"batch_size\": 100, \n",
    "              \"buffer_size\": 1000000, \n",
    "              \"learning_rate\": 0.001}\n",
    "\n",
    "model_td3 = agent.get_model(\"td3\",model_kwargs = TD3_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OSRxNYAxdKpU",
    "outputId": "ddc4193c-884b-4a2c-9e49-31397e2cfbec"
   },
   "outputs": [],
   "source": [
    "trained_td3 = agent.train_model(model=model_td3, \n",
    "                             tb_log_name='td3',\n",
    "                             total_timesteps=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dr49PotrfG01"
   },
   "source": [
    "### Model 5: SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwOhVjqRkCdM",
    "outputId": "5ad99882-367d-49ce-d83e-124396074c12"
   },
   "outputs": [],
   "source": [
    "agent = DRLAgent(env = env_train)\n",
    "SAC_PARAMS = {\n",
    "    \"batch_size\": 128,\n",
    "    \"buffer_size\": 1000000,\n",
    "    \"learning_rate\": 0.0001,\n",
    "    \"learning_starts\": 100,\n",
    "    \"ent_coef\": \"auto_0.1\",\n",
    "}\n",
    "\n",
    "model_sac = agent.get_model(\"sac\",model_kwargs = SAC_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8RSdKCckJyH",
    "outputId": "8dfca8da-65ea-4e61-f7c7-16094ea00cc0"
   },
   "outputs": [],
   "source": [
    "trained_sac = agent.train_model(model=model_sac, \n",
    "                             tb_log_name='sac',\n",
    "                             total_timesteps=80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2wZgkQXh1jE"
   },
   "source": [
    "## Trading\n",
    "Assume that we have $1,000,000 initial capital at 2019-01-01. We use the DDPG model to trade Dow jones 30 stocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEv5KGC8h1jE"
   },
   "source": [
    "### Set turbulence threshold\n",
    "Set the turbulence threshold to be greater than the maximum of insample turbulence data, if current turbulence index is greater than the threshold, then we assume that the current market is volatile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "efwBi84ch1jE"
   },
   "outputs": [],
   "source": [
    "data_turbulence = processed_full[(processed_full.date<'2019-01-01') & (processed_full.date>='2009-01-01')]\n",
    "insample_turbulence = data_turbulence.drop_duplicates(subset=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VHZMBpSqh1jG",
    "outputId": "f750f515-9f4f-4adb-846e-ea0bdf15ea6b"
   },
   "outputs": [],
   "source": [
    "insample_turbulence.turbulence.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yuwDPkV9h1jL"
   },
   "outputs": [],
   "source": [
    "turbulence_threshold = np.quantile(insample_turbulence.turbulence.values,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwoz_7VSh1jO",
    "outputId": "37894e93-d22e-4e3f-f23a-d3ca08bf8342"
   },
   "outputs": [],
   "source": [
    "turbulence_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5mmgQF_h1jQ"
   },
   "source": [
    "### Trade\n",
    "\n",
    "DRL model needs to update periodically in order to take full advantage of the data, ideally we need to retrain our model yearly, quarterly, or monthly. We also need to tune the parameters along the way, in this notebook I only use the in-sample data from 2009-01 to 2018-12 to tune the parameters once, so there is some alpha decay here as the length of trade date extends. \n",
    "\n",
    "Numerous hyperparameters – e.g. the learning rate, the total number of samples to train on – influence the learning process and are usually determined by testing some variations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eLOnL5eYh1jR"
   },
   "outputs": [],
   "source": [
    "trade = data_split(processed_full, '2019-01-01','2021-01-01')\n",
    "e_trade_gym = StockTradingEnv(df = trade, turbulence_threshold = 380, **env_kwargs)\n",
    "env_trade, obs_trade = e_trade_gym.get_sb_env()\n",
    "\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(model=trained_sac,\n",
    "                        test_data = trade,\n",
    "                        test_env = env_trade,\n",
    "                        test_obs = obs_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ERxw3KqLkcP4",
    "outputId": "cbb465c9-38dc-4d88-e79a-6ae29025164b"
   },
   "outputs": [],
   "source": [
    "df_account_value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194
    },
    "id": "2yRkNguY5yvp",
    "outputId": "53ec139f-88e7-4291-cf11-8e6766184265"
   },
   "outputs": [],
   "source": [
    "df_account_value.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 328
    },
    "id": "nFlK5hNbWVFk",
    "outputId": "06fe8d38-8724-4cea-f6ce-7a2af821ebab"
   },
   "outputs": [],
   "source": [
    "df_actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6vvNSC6h1jZ"
   },
   "source": [
    "<a id='6'></a>\n",
    "# Part 7: Backtest Our Strategy\n",
    "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lr2zX7ZxNyFQ"
   },
   "source": [
    "<a id='6.1'></a>\n",
    "## 7.1 BackTestStats\n",
    "pass in df_account_value, this information is stored in env class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nzkr9yv-AdV_",
    "outputId": "1053083a-d74c-48b0-a623-de33282e2fff"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Backtest Results===========\")\n",
    "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
    "\n",
    "perf_stats_all = BackTestStats(account_value=df_account_value)\n",
    "perf_stats_all = pd.DataFrame(perf_stats_all)\n",
    "perf_stats_all.to_csv(\"./\"+config.RESULTS_DIR+\"/perf_stats_all_\"+now+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9U6Suru3h1jc"
   },
   "source": [
    "<a id='6.2'></a>\n",
    "## 7.2 BackTestPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lKRGftSS7pNM",
    "outputId": "4f77cef2-3934-444a-cacc-4ed8f94514ae"
   },
   "outputs": [],
   "source": [
    "print(\"==============Compare to DJIA===========\")\n",
    "%matplotlib inline\n",
    "# S&P 500: ^GSPC\n",
    "# Dow Jones Index: ^DJI\n",
    "# NASDAQ 100: ^NDX\n",
    "BackTestPlot(df_account_value, \n",
    "             baseline_ticker = '^DJI', \n",
    "             baseline_start = '2019-01-01',\n",
    "             baseline_end = '2021-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlLT9_5WN478"
   },
   "source": [
    "<a id='6.3'></a>\n",
    "## 7.3 Baseline Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YktexHcqh1jc",
    "outputId": "38566531-a3a0-4705-db30-d437e8f8fc73"
   },
   "outputs": [],
   "source": [
    "print(\"==============Get Baseline Stats===========\")\n",
    "baesline_perf_stats=BaselineStats('^DJI',\n",
    "                                  baseline_start = '2019-01-01',\n",
    "                                  baseline_end = '2021-01-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6W2J57ch1j9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "uijiWgkuh1jB",
    "MRiOtrywfAo1",
    "_gDkU-j-fCmZ",
    "3Zpv4S0-fDBv"
   ],
   "include_colab_link": true,
   "name": "FinRL_multiple_stock_trading.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
